#!/usr/bin/env python3
# ruff: noqa: T201

"""Debug the exact mojibake issue we're seeing."""

import os
import sys

# Add the parent directory to sys.path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def test_mojibake_debug():
    """Debug the specific mojibake we're seeing."""
    print(  # noqa: T201"ğŸ” MOJIBAKE DEBUG TEST")
    print(  # noqa: T201"=" * 22)

    # The mojibake string from the user's output
    mojibake = "charset=Unicode ç¬€âˆ€çˆ€æ”€çŒ€æ¼€ç”€çˆ€æŒ€æ”€â´€çŒ€ç€æ„€æŒ€æ¬€âˆ€ã¨€ç¬€âˆ€æŒ€æ°€æ„€çŒ€çŒ€å¼€ç€ç¤€ç€€æ”€âˆ€ã¨€âˆ€äŒ€æ €æ”€æŒ€æ¬€ç€€æ¼€æ¤€æ¸€ç€ä°€æ¼€æ„€æ€æ”€çˆ€åŒ€æ¤€æ´€ç€€æ°€æ”€âˆ€â°€âˆ€æ¤€æ¸€ç€€ç”€ç€çŒ€âˆ€ã¨€ç¬€âˆ€æŒ€æ¬€ç€€ç€å¼€æ¸€æ„€æ´€æ”€âˆ€ã¨€âˆ€ç”€çˆ€æ¸€ã¨€æ„€æ¤€çˆ€ã¨€çŒ€æ€ç €æ°€ã¨€æŒ€æ €æ”€æŒ€æ¬€ç€€æ¼€æ¤€æ¸€ç€ã¨€æŒ€æ¤€ç˜€æ¤€ç€æ„€æ¤€ã¨€ãˆ€ã €ã €ã”€ã €ã€ä€€ãŒ€ãˆ€ã€ã˜€ã„€ã¤€âˆ€"

    print(  # noqa: T201f"Input string: {mojibake[:100]}...")
    print(  # noqa: T201f"Length: {len(mojibake)}")

    # This looks like UTF-16 encoded as UTF-8, let's try to decode it
    print(  # noqa: T201"\nğŸ”§ DECODING ATTEMPTS")
    print(  # noqa: T201"-" * 20)

    # Try to encode back to bytes and decode as UTF-16
    try:
        # The part after "charset=Unicode "
        unicode_part = mojibake[len("charset=Unicode ") :]
        print(  # noqa: T201f"Unicode part: {unicode_part[:50]}...")

        # Encode to UTF-8 bytes then decode as UTF-16
        utf8_bytes = unicode_part.encode("utf-8")
        print(  # noqa: T201f"UTF-8 bytes: {utf8_bytes[:50]}...")

        # Try UTF-16 decoding
        utf16_decoded = utf8_bytes.decode("utf-16le", errors="ignore")
        print(  # noqa: T201f"UTF-16 decoded: {utf16_decoded[:100]}...")

        # Check if it looks like JSON
        if utf16_decoded.startswith('{"') or '"class_type"' in utf16_decoded:
            print(  # noqa: T201"âœ… Looks like valid JSON after decoding!")
        else:
            print(  # noqa: T201"âŒ Still doesn't look like JSON")

    except Exception as e:
        print(  # noqa: T201f"âŒ UTF-16 decoding failed: {e}")

    # Try our robust decoder
    print(  # noqa: T201"\nğŸ”§ TESTING OUR ROBUST DECODER")
    print(  # noqa: T201"-" * 33)

    try:
        from dataset_tools.metadata_engine.context_preparation import ContextDataPreparer

        preparer = ContextDataPreparer()

        # Simulate the charset=Unicode prefix format
        fake_bytes = f"charset=Unicode {mojibake[len('charset=Unicode ') :]}".encode()
        print(  # noqa: T201f"Fake bytes: {fake_bytes[:50]}...")

        decoded = preparer._decode_usercomment_bytes_robust(fake_bytes)
        if decoded:
            print(  # noqa: T201f"âœ… Robust decoder SUCCESS: {len(decoded)} chars")
            print(  # noqa: T201f"Preview: {decoded[:100]}...")

            if decoded.startswith('{"') or '"class_type"' in decoded:
                print(  # noqa: T201"âœ… Looks like valid JSON!")
            else:
                print(  # noqa: T201"âŒ Still doesn't look like JSON")
        else:
            print(  # noqa: T201"âŒ Robust decoder returned empty")

    except Exception as e:
        print(  # noqa: T201f"âŒ Robust decoder error: {e}")
        import traceback

        traceback.print_exc()

    print(  # noqa: T201"\nğŸ¯ ANALYSIS:")
    print(  # noqa: T201"This appears to be UTF-16 data that was incorrectly decoded as UTF-8")
    print(  # noqa: T201"The 'charset=Unicode' prefix indicates it should be UTF-16LE encoded")
    print(  # noqa: T201"Our robust decoder should handle this pattern")


if __name__ == "__main__":
    test_mojibake_debug()
