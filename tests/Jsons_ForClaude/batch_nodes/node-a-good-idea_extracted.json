[
    {
        "id": 6,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "mathematflake mathematswirl tessswirl flake mathematfractured simulation generative gpu zanzimathematswirl peumandelstructure geomeowo zanzitetradecay zanziflake simulation pepperoni generative mathematzanziebony simulation displacement generative mathematcloak aluminmathematdeeply kailmandala swirl tamine mathematzanzirender methylmathematrender mathematsalesman myart map depiction einstein marijuana uav infrared geoimaging lsd pyramid illuminati radar mandelmicroscopy statistics trippy seizure psychedelic motorola detection desktop average tracdataviz pixelart colorful hdr mathemattetris lsd swirl mathemattamine mathematmathematcollagen lsd mathematfluctucarved mandelsurface mathematcollagen generative simulation"
        }
    },
    {
        "id": 10,
        "name": "VAELoader",
        "prompts": {
            "text": "ae.safetensors"
        }
    },
    {
        "id": 11,
        "name": "DualCLIPLoader",
        "prompts": {
            "text": "t5xxl_fp8_e4m3fn.safetensors",
            "text_2": "ViT-L-14-BEST-smooth-GmP-TE-only-HF-format.safetensors"
        }
    },
    {
        "id": 27,
        "name": "EmptySD3LatentImage"
    },
    {
        "id": 30,
        "name": "ModelSamplingFlux"
    },
    {
        "id": 34,
        "name": "PrimitiveNode"
    },
    {
        "id": 35,
        "name": "PrimitiveNode"
    },
    {
        "id": 159,
        "name": "UNETLoader",
        "prompts": {
            "text": "flux1-dev.safetensors"
        }
    },
    {
        "id": 255,
        "name": "CLIPshuffleLayersNode",
        "prompts": {
            "text": "2,3,4,5,8,9,10,11,12,13"
        }
    },
    {
        "id": 269,
        "name": "ShuffleFluxLayersNode",
        "prompts": {
            "text": "8,9,10,11,12,13"
        }
    },
    {
        "id": 284,
        "name": "CLIPTextEncodeFlux",
        "prompts": {
            "text": "hideous artichosurrealism vangogh heap corrupt tangled mashup impressionism vangogh fractal hermit horrifying eyed psychedstare herbal mackerel eternity prohibition horrifying triple-eyestriplet mandeloctozoomzoomresult asdfghjgenerating recurtriplets"
        }
    },
    {
        "id": 287,
        "name": "DF_To_text_(Debug)",
        "prompts": {
            "text": "tensor([1.0000, 0.9995, 0.9991, 0.9988, 0.9970, 0.9961, 0.9910, 0.9845, 0.9800,\n        0.9780, 0.9620, 0.9400, 0.9300, 0.9020, 0.8820, 0.8420, 0.8120, 0.7650,\n        0.6540, 0.5000, 0.3500])"
        }
    },
    {
        "id": 303,
        "name": "CustomScheduler"
    },
    {
        "id": 306,
        "name": "Reroute"
    },
    {
        "id": 327,
        "name": "PlotBlockParams"
    },
    {
        "id": 330,
        "name": "DF_To_text_(Debug)",
        "prompts": {
            "text": "diffusion_model.double_blocks.5.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.5.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.5.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.5.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.5.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.5.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.6.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.6.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.6.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.6.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.6.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.6.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.7.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.7.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.7.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.7.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.7.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.7.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.12.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.12.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.12.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.12.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.12.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.12.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.13.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.13.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.13.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.13.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.13.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.13.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.14.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.14.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.14.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.14.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.14.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.14.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.15.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.15.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.15.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.15.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.15.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.15.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.16.txt_mod.lin.weight: 0.5\ndiffusion_model.double_blocks.16.txt_mod.lin.bias: 0.5\ndiffusion_model.double_blocks.16.txt_attn.qkv.weight: 0.5\ndiffusion_model.double_blocks.16.txt_attn.qkv.bias: 0.5\ndiffusion_model.double_blocks.16.txt_attn.proj.weight: 0.5\ndiffusion_model.double_blocks.16.txt_attn.proj.bias: 0.5\ndiffusion_model.double_blocks.5.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.5.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.5.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.5.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.5.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.5.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.6.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.6.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.6.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.6.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.6.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.6.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.7.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.7.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.7.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.7.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.7.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.7.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.12.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.12.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.12.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.12.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.12.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.12.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.13.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.13.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.13.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.13.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.13.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.13.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.14.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.14.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.14.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.14.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.14.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.14.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.15.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.15.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.15.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.15.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.15.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.15.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.16.txt_mod.lin.weight: 0.8\ndiffusion_model.double_blocks.16.txt_mod.lin.bias: 0.8\ndiffusion_model.double_blocks.16.txt_attn.qkv.weight: 0.8\ndiffusion_model.double_blocks.16.txt_attn.qkv.bias: 0.8\ndiffusion_model.double_blocks.16.txt_attn.proj.weight: 0.8\ndiffusion_model.double_blocks.16.txt_attn.proj.bias: 0.8\ndiffusion_model.double_blocks.5.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.5.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.5.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.5.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.5.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.5.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.6.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.6.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.6.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.6.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.6.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.6.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.7.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.7.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.7.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.7.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.7.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.7.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.12.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.12.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.12.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.12.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.12.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.12.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.13.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.13.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.13.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.13.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.13.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.13.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.14.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.14.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.14.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.14.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.14.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.14.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.15.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.15.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.15.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.15.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.15.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.15.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.16.txt_mod.lin.weight: 1.0\ndiffusion_model.double_blocks.16.txt_mod.lin.bias: 1.0\ndiffusion_model.double_blocks.16.txt_attn.qkv.weight: 1.0\ndiffusion_model.double_blocks.16.txt_attn.qkv.bias: 1.0\ndiffusion_model.double_blocks.16.txt_attn.proj.weight: 1.0\ndiffusion_model.double_blocks.16.txt_attn.proj.bias: 1.0\ndiffusion_model.double_blocks.5.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.5.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.5.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.5.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.5.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.5.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.6.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.6.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.6.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.6.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.6.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.6.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.7.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.7.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.7.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.7.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.7.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.7.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.12.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.12.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.12.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.12.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.12.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.12.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.13.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.13.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.13.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.13.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.13.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.13.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.14.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.14.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.14.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.14.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.14.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.14.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.15.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.15.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.15.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.15.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.15.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.15.txt_attn.proj.bias: 1.1\ndiffusion_model.double_blocks.16.txt_mod.lin.weight: 1.1\ndiffusion_model.double_blocks.16.txt_mod.lin.bias: 1.1\ndiffusion_model.double_blocks.16.txt_attn.qkv.weight: 1.1\ndiffusion_model.double_blocks.16.txt_attn.qkv.bias: 1.1\ndiffusion_model.double_blocks.16.txt_attn.proj.weight: 1.1\ndiffusion_model.double_blocks.16.txt_attn.proj.bias: 1.1"
        }
    },
    {
        "id": 332,
        "name": "SaveImage",
        "prompts": {
            "text": "BlockPatcher"
        }
    },
    {
        "id": 333,
        "name": "VAEDecode"
    },
    {
        "id": 334,
        "name": "Note",
        "prompts": {
            "text": "Best for starters:\n\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\n\n\nDefault:\n\ndouble_blocks\\.([0-9]+)\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\nsingle_blocks\\.([0-9]+)\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.1\n\n\nEmphasize the Early Blocks\n\ndouble_blocks\\.([0-5])\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.5\nsingle_blocks\\.([0-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.5\n\n\nReduce Influence on Later Blocks\n\ndouble_blocks\\.(3[0-7]|2[5-9])\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.7\nsingle_blocks\\.(3[0-7]|2[5-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.7\n\n\nEnhance Specific Components within Middle Blocks\n\n\ndouble_blocks\\.1[0-7]\\.(img|txt)_attn\\.(qkv|proj)\\.(weight|bias)=1.3\nsingle_blocks\\.1[0-7]\\.linear2\\.(weight|bias)=1.3\n\n\nAlternate Enhancements in Odd-Indexed Blocks\n\n\ndouble_blocks\\.(2[8-9]|3[0-7])\\.(img|txt)_mlp\\.[02]\\.(lin|proj)\\.(weight|bias)=1.4\nsingle_blocks\\.(2[8-9]|3[0-7])\\.modulation\\.lin\\.(weight|bias)=1.4\n\n\nIncrease Focus on Attention Projections Across the Entire Model (not a good idea, lol)\n\n\ndouble_blocks\\.([0-9]|[1-3][0-7])\\.(img|txt)_attn\\.(proj)\\.(weight|bias)=1.6\nsingle_blocks\\.([0-9]|[1-3][0-7])\\.linear2\\.(weight|bias)=1.6\n\n\nGradual Decrease in Scaling Factors Through the Model\n\ndouble_blocks\\.([0-9])\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|proj)\\.(weight|bias)=1.4\ndouble_blocks\\.1[0-9]\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|proj)\\.(weight|bias)=1.2\ndouble_blocks\\.2[0-9]\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|proj)\\.(weight|bias)=1.0\ndouble_blocks\\.3[0-7]\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|proj)\\.(weight|bias)=0.8\n\nsingle_blocks\\.([0-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.4\nsingle_blocks\\.1[0-9]\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.2\nsingle_blocks\\.2[0-9]\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.0\nsingle_blocks\\.3[0-7]\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\n\n\n\nDropping Text Influence in Later Blocks for single_blocks (it's all going downhill from here!)\n\nsingle_blocks\\.(2[5-9]|3[0-7])\\.linear2\\.(weight|bias)=0.0\nsingle_blocks\\.(2[5-9]|3[0-7])\\.modulation\\.lin\\.(weight|bias)=0.0\n\n\nDropping Text Influence in Later Blocks for double_blocks (don't do that, flux needs a text)\n\ndouble_blocks\\.(2[5-9]|3[0-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.0\n\n\nDropping Text Influence in Later Blocks for Both single_blocks and double_blocks (it's a bad idea, really)\n\nsingle_blocks\\.(2[5-9]|3[0-7])\\.linear2\\.(weight|bias)=0.0\nsingle_blocks\\.(2[5-9]|3[0-7])\\.modulation\\.lin\\.(weight|bias)=0.0\n\ndouble_blocks\\.(2[5-9]|3[0-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.0\n\n\nDump text in intermediate layers only, single_blocks (all of that ruins it, srsly):\n\nsingle_blocks\\.(1[0-9])\\.linear2\\.(weight|bias)=0.0\nsingle_blocks\\.(1[0-9])\\.modulation\\.lin\\.(weight|bias)=0.0\n\n\nLower text attention (zero is absolutely destructive!)\n\nsingle_blocks\\.(1[0-9])\\.txt_attn\\.(qkv|proj)\\.(weight|bias)=0.05\ndouble_blocks\\.(1[1-6])\\.txt_attn\\.(qkv|proj)\\.(weight|bias)=0.0\n\n\n\nAdd your own regex here:\n"
        }
    },
    {
        "id": 336,
        "name": "Reroute"
    },
    {
        "id": 337,
        "name": "Reroute"
    },
    {
        "id": 338,
        "name": "Reroute"
    },
    {
        "id": 340,
        "name": "CLIPTextEncodeFlux",
        "prompts": {
            "text": "rubbed cheyenne asparagus rebounds \u30adlightweight spidey underrated hallucindoodled glitchcritter photo kaleidononsense"
        }
    },
    {
        "id": 341,
        "name": "Reroute"
    },
    {
        "id": 342,
        "name": "Reroute"
    },
    {
        "id": 343,
        "name": "ConditioningCombine"
    },
    {
        "id": 344,
        "name": "Reroute"
    },
    {
        "id": 347,
        "name": "Reroute"
    },
    {
        "id": 360,
        "name": "Reroute"
    },
    {
        "id": 363,
        "name": "Reroute"
    },
    {
        "id": 364,
        "name": "Reroute"
    },
    {
        "id": 369,
        "name": "FluxBlockPatcherSampler",
        "prompts": {
            "text": "dpmpp_2s_ancestral",
            "text_2": "double_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.8\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.0\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\n\n\n\n\n"
        }
    },
    {
        "id": 372,
        "name": "Reroute"
    },
    {
        "id": 374,
        "name": "Reroute"
    },
    {
        "id": 375,
        "name": "Reroute"
    },
    {
        "id": 376,
        "name": "Reroute"
    },
    {
        "id": 377,
        "name": "Reroute"
    },
    {
        "id": 379,
        "name": "Reroute"
    },
    {
        "id": 380,
        "name": "Reroute"
    },
    {
        "id": 381,
        "name": "Reroute"
    },
    {
        "id": 382,
        "name": "Reroute"
    },
    {
        "id": 383,
        "name": "Reroute"
    },
    {
        "id": 384,
        "name": "Reroute"
    },
    {
        "id": 387,
        "name": "Reroute"
    },
    {
        "id": 388,
        "name": "Reroute"
    },
    {
        "id": 389,
        "name": "Reroute"
    },
    {
        "id": 390,
        "name": "SaveImage"
    },
    {
        "id": 391,
        "name": "Reroute"
    },
    {
        "id": 393,
        "name": "Reroute"
    },
    {
        "id": 394,
        "name": "Reroute"
    },
    {
        "id": 395,
        "name": "Reroute"
    },
    {
        "id": 401,
        "name": "Reroute"
    },
    {
        "id": 402,
        "name": "Reroute"
    },
    {
        "id": 403,
        "name": "Reroute"
    },
    {
        "id": 404,
        "name": "LoraLoaderModelOnly",
        "prompts": {
            "text": "dream_flux_four_lora_v4_000001250.safetensors"
        }
    },
    {
        "id": 407,
        "name": "Note",
        "prompts": {
            "text": "single_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.3\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\nsingle_blocks\\.([0-9]+)\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.1\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.3\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.8\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.2\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.5\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.9\ndouble_blocks\\.([0-9]+)\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.01\ndouble_blocks\\.([0-9]+)\\.(img|txt)_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\n\n\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.3\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.4\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.6\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.7\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.8\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.9\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.0\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.2\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.25\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.3\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.35\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.4\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.45\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.5\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.55\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.6\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.65\ndouble_blocks\\.([5-7]|1[2-6])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.7\n\n\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.3\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.4\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.6\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.7\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.8\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.9\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.0\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.2\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.25\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.3\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.35\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.4\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.45\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.5\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.55\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.6\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.65\ndouble_blocks\\.([1-9])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.7\n\n\n\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.3\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.4\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.5\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.6\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.7\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.8\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=0.9\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.0\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.1\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.2\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.25\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.3\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.35\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.4\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.45\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.5\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.55\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.6\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.65\ndouble_blocks\\.(1[1-7])\\.txt_(mod|attn|mlp\\.[02])\\.(lin|qkv|proj)\\.(weight|bias)=1.7\n\n\n\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.1\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.2\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.3\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.4\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.6\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.7\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.9\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.0\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.1\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.2\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.3\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.4\nsingle_blocks\\.([1-5])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.5\n\n\n\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.1\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.2\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.3\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.4\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.6\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.7\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.9\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.0\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.1\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.2\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.3\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.4\nsingle_blocks\\.(1[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.5\n\n\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.1\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.2\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.3\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.4\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.6\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.7\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.9\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.0\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.1\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.2\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.3\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.4\nsingle_blocks\\.(2[1-9])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.5\n\n\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.1\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.2\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.3\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.4\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.5\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.6\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.7\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.8\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=0.9\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.0\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.1\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.2\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.3\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.4\nsingle_blocks\\.(3[1-7])\\.(linear[12]|modulation\\.lin)\\.(weight|bias)=1.5\n\n\n\n"
        }
    }
]