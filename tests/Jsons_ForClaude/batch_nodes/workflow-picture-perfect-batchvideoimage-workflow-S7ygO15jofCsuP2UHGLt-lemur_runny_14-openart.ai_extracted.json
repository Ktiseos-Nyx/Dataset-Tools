[
    {
        "id": 332,
        "name": "CheckpointLoaderSimple",
        "prompts": {
            "text": "cuteheaven_v20.safetensors"
        }
    },
    {
        "id": 335,
        "name": "VAELoader",
        "prompts": {
            "text": "vae-ft-mse-840000-ema-pruned.ckpt"
        }
    },
    {
        "id": 423,
        "name": "CLIPSetLastLayer"
    },
    {
        "id": 426,
        "name": "ImageUpscaleWithModel"
    },
    {
        "id": 427,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 429,
        "name": "Number Operation",
        "prompts": {
            "text": "multiplication"
        }
    },
    {
        "id": 430,
        "name": "Image Size to Number"
    },
    {
        "id": 432,
        "name": "Number Operation",
        "prompts": {
            "text": "multiplication"
        }
    },
    {
        "id": 433,
        "name": "Constant Number"
    },
    {
        "id": 434,
        "name": "UpscaleModelLoader",
        "prompts": {
            "text": "4x_NMKD-Siax_200k.pth"
        }
    },
    {
        "id": 437,
        "name": "Image Lucy Sharpen"
    },
    {
        "id": 438,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 440,
        "name": "ImageUpscaleWithModel"
    },
    {
        "id": 441,
        "name": "Number Operation",
        "prompts": {
            "text": "multiplication"
        }
    },
    {
        "id": 442,
        "name": "Image Size to Number"
    },
    {
        "id": 443,
        "name": "Number Operation",
        "prompts": {
            "text": "multiplication"
        }
    },
    {
        "id": 444,
        "name": "Constant Number"
    },
    {
        "id": 472,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips teasing the viewer in a very dark bedroom, she is smiling menacingly, laughing, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 551,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, helmet, glasses, NSFW"
        }
    },
    {
        "id": 555,
        "name": "CheckpointLoaderSimple",
        "prompts": {
            "text": "theSRWondermix_v2.safetensors"
        }
    },
    {
        "id": 556,
        "name": "VAELoader",
        "prompts": {
            "text": "vae-ft-mse-840000-ema-pruned.ckpt"
        }
    },
    {
        "id": 558,
        "name": "PrimitiveNode"
    },
    {
        "id": 561,
        "name": "CLIPSetLastLayer"
    },
    {
        "id": 744,
        "name": "EmptyLatentImage"
    },
    {
        "id": 745,
        "name": "EmptyLatentImage"
    },
    {
        "id": 746,
        "name": "EmptyLatentImage"
    },
    {
        "id": 747,
        "name": "EmptyLatentImage"
    },
    {
        "id": 748,
        "name": "EmptyLatentImage"
    },
    {
        "id": 749,
        "name": "EmptyLatentImage"
    },
    {
        "id": 750,
        "name": "EmptyLatentImage"
    },
    {
        "id": 751,
        "name": "Reroute"
    },
    {
        "id": 752,
        "name": "Reroute"
    },
    {
        "id": 753,
        "name": "Reroute"
    },
    {
        "id": 754,
        "name": "Reroute"
    },
    {
        "id": 755,
        "name": "Reroute"
    },
    {
        "id": 756,
        "name": "Reroute"
    },
    {
        "id": 757,
        "name": "Reroute"
    },
    {
        "id": 758,
        "name": "EmptyLatentImage"
    },
    {
        "id": 759,
        "name": "EmptyLatentImage"
    },
    {
        "id": 760,
        "name": "EmptyLatentImage"
    },
    {
        "id": 761,
        "name": "EmptyLatentImage"
    },
    {
        "id": 762,
        "name": "EmptyLatentImage"
    },
    {
        "id": 763,
        "name": "EmptyLatentImage"
    },
    {
        "id": 764,
        "name": "EmptyLatentImage"
    },
    {
        "id": 765,
        "name": "Reroute"
    },
    {
        "id": 766,
        "name": "Reroute"
    },
    {
        "id": 767,
        "name": "Reroute"
    },
    {
        "id": 768,
        "name": "Reroute"
    },
    {
        "id": 769,
        "name": "Reroute"
    },
    {
        "id": 770,
        "name": "Reroute"
    },
    {
        "id": 771,
        "name": "Reroute"
    },
    {
        "id": 772,
        "name": "PrimitiveNode"
    },
    {
        "id": 773,
        "name": "Reroute"
    },
    {
        "id": 787,
        "name": "Reroute"
    },
    {
        "id": 794,
        "name": "PreviewImage"
    },
    {
        "id": 815,
        "name": "Reroute"
    },
    {
        "id": 816,
        "name": "Reroute"
    },
    {
        "id": 817,
        "name": "Reroute"
    },
    {
        "id": 818,
        "name": "Reroute"
    },
    {
        "id": 863,
        "name": "Note",
        "prompts": {
            "text": "Loading the Checkpoints, VAE, and clip skip options. \n\nDefault it loads the VAE separate from the checkpoints as some don't have a vae, and sometimes you just want to use the one you want.\n\nIf you want to load the VAE from the checkpoint, drag the VAE red circle from the checkpoint to the bus next to it. \n\n2 loras can be loaded per bus.\nLCM lora should be loaded last of the loras.  I used LCM lora at 0.6 strength.\nCan add additional loras between the two already there quite easily if you need to.\n\nI recommend using a fixed seed but random works just fine\n\nExtra settings - These can be enabled and disabled by just bypassing the node for on and off.\n\nPatchModelAddDownscale - this node can help you make larger base images without distorted body parts.  1.5 can make 1024 or 720p images with this option as base images.  \nNot 100% sure, but The optional Block Number seems to be an aspect ratio thing. I use 3 for square, 4 for widescreen, and 2 for portrait.  I could be wrong here.\n\nFreeU 1 and 2.\nThese can be useful in both video and images.  Sometimes they dont help. Just an option.\n\nRescale CFG. - this is used because I am using an LCM lora with a regular model forcing a lower CFG than I would like.  This makes your prompt matter more. Highly recommended when using LCM. Setting of 0.4-0.8 is a range I use mostly sitting at 0.6. "
        }
    },
    {
        "id": 864,
        "name": "Note",
        "prompts": {
            "text": "Depending on your base size, you can upscale here from 1.0-3.0\n\nCropping the original base image/video \n\nfor videos you can do 512x512 base for best motion and then crop to your liking here for the upscale, upscale a bit more in this case.\n\nYou can choose to upscale with or without a model, bypass upscale with model to skip that step, It's not needed here, but it's an option.\n\nLatent Interposer lets you change the latent from xl to 1.5 and back without the vaedeocode. v1 is 1.5 xl is xl  Use this when you are using the latent upscale and are swapping in/out of xl and 1.5"
        }
    },
    {
        "id": 868,
        "name": "EmptyLatentImage"
    },
    {
        "id": 887,
        "name": "LoraLoader",
        "prompts": {
            "text": "lcm\\SD1.5\\pytorch_lora_weights.safetensors"
        }
    },
    {
        "id": 888,
        "name": "LoraLoader",
        "prompts": {
            "text": "hip_sway_dancev1.safetensors"
        }
    },
    {
        "id": 889,
        "name": "LoraLoader",
        "prompts": {
            "text": "hip_sway_dancev1.safetensors"
        }
    },
    {
        "id": 890,
        "name": "LoraLoader",
        "prompts": {
            "text": "lcm\\SD1.5\\pytorch_lora_weights.safetensors"
        }
    },
    {
        "id": 922,
        "name": "PatchModelAddDownscale"
    },
    {
        "id": 923,
        "name": "PatchModelAddDownscale"
    },
    {
        "id": 1004,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips in a very dark bedroom, she is smiling menacingly, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 1005,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, (nipple:1.2)"
        }
    },
    {
        "id": 1014,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1015,
        "name": "ControlNetLoaderAdvanced",
        "prompts": {
            "text": "control_v11f1e_sd15_tile_fp16.safetensors"
        }
    },
    {
        "id": 1046,
        "name": "VAEEncode"
    },
    {
        "id": 1242,
        "name": "FreeU"
    },
    {
        "id": 1243,
        "name": "FreeU"
    },
    {
        "id": 1244,
        "name": "FreeU_V2"
    },
    {
        "id": 1245,
        "name": "FreeU_V2"
    },
    {
        "id": 1246,
        "name": "RescaleCFG"
    },
    {
        "id": 1247,
        "name": "RescaleCFG"
    },
    {
        "id": 1249,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips teasing the viewer in a very dark bedroom, she is smiling menacingly, laughing, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 1250,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, helmet, glasses, NSFW"
        }
    },
    {
        "id": 1290,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips teasing the viewer in a very dark bedroom, she is smiling menacingly, laughing, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 1291,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, helmet, glasses, NSFW"
        }
    },
    {
        "id": 1292,
        "name": "Reroute"
    },
    {
        "id": 1295,
        "name": "Reroute"
    },
    {
        "id": 1296,
        "name": "LatentUpscaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 1297,
        "name": "Reroute"
    },
    {
        "id": 1298,
        "name": "Reroute"
    },
    {
        "id": 1330,
        "name": "Reroute"
    },
    {
        "id": 1339,
        "name": "Reroute"
    },
    {
        "id": 1341,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1343,
        "name": "PreviewImage"
    },
    {
        "id": 1344,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1362,
        "name": "LatentInterposer"
    },
    {
        "id": 1371,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips in a very dark bedroom, she is smiling menacingly, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 1372,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, (nipple:1.2)"
        }
    },
    {
        "id": 1373,
        "name": "Reroute"
    },
    {
        "id": 1374,
        "name": "Reroute"
    },
    {
        "id": 1375,
        "name": "Reroute"
    },
    {
        "id": 1376,
        "name": "Reroute"
    },
    {
        "id": 1377,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1378,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "1girl, a realistic video of a beautiful demon succubus swaying her hips in a very dark bedroom, she is smiling menacingly, glowing red eyes, thick thighs, thigh gap, thigh high socks, horns, corset, panties, skirt, (hip sway:1.2)"
        }
    },
    {
        "id": 1379,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, embedding:bad-hands-5, lace, frills, jewellery, (nipple:1.2)"
        }
    },
    {
        "id": 1402,
        "name": "Reroute"
    },
    {
        "id": 1406,
        "name": "ImageSelector"
    },
    {
        "id": 1407,
        "name": "ImageSelector"
    },
    {
        "id": 1421,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 1432,
        "name": "VHS_VideoCombine"
    },
    {
        "id": 1434,
        "name": "VHS_VideoCombine"
    },
    {
        "id": 1442,
        "name": "ADE_AnimateDiffLoaderWithContext",
        "prompts": {
            "text": "v3_sd15_mm.ckpt",
            "text_2": "sqrt_linear (AnimateDiff)"
        }
    },
    {
        "id": 1446,
        "name": "VAEEncode"
    },
    {
        "id": 1449,
        "name": "ADE_AnimateDiffUnload"
    },
    {
        "id": 1450,
        "name": "PrepImageForClipVision"
    },
    {
        "id": 1481,
        "name": "ADE_AnimateDiffUniformContextOptions"
    },
    {
        "id": 1482,
        "name": "ADE_AnimateDiffLoaderWithContext",
        "prompts": {
            "text": "v3_sd15_mm.ckpt",
            "text_2": "sqrt_linear (AnimateDiff)"
        }
    },
    {
        "id": 1483,
        "name": "ADE_AnimateDiffModelSettingsSimple"
    },
    {
        "id": 1484,
        "name": "PrimitiveNode"
    },
    {
        "id": 1485,
        "name": "PrimitiveNode"
    },
    {
        "id": 1486,
        "name": "PrimitiveNode"
    },
    {
        "id": 1522,
        "name": "Reroute"
    },
    {
        "id": 1527,
        "name": "IPAdapterEncoder"
    },
    {
        "id": 1529,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1530,
        "name": "Reroute"
    },
    {
        "id": 1532,
        "name": "Image To Mask"
    },
    {
        "id": 1534,
        "name": "PrepImageForClipVision"
    },
    {
        "id": 1535,
        "name": "IPAdapterEncoder"
    },
    {
        "id": 1536,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1538,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1539,
        "name": "ADE_AnimateDiffUnload"
    },
    {
        "id": 1541,
        "name": "Reroute"
    },
    {
        "id": 1542,
        "name": "Reroute"
    },
    {
        "id": 1554,
        "name": "Bounded Image Crop"
    },
    {
        "id": 1555,
        "name": "Inset Image Bounds"
    },
    {
        "id": 1556,
        "name": "Image Bounds"
    },
    {
        "id": 1557,
        "name": "PrimitiveNode"
    },
    {
        "id": 1558,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "v3_sd15_mm.ckpt"
        }
    },
    {
        "id": 1559,
        "name": "PrimitiveNode"
    },
    {
        "id": 1560,
        "name": "ADE_AnimateDiffLoRALoader",
        "prompts": {
            "text": "v2_lora_ZoomOut.ckpt"
        }
    },
    {
        "id": 1561,
        "name": "PrimitiveNode"
    },
    {
        "id": 1562,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "sqrt_linear (AnimateDiff)"
        }
    },
    {
        "id": 1563,
        "name": "Reroute"
    },
    {
        "id": 1564,
        "name": "PrimitiveNode"
    },
    {
        "id": 1565,
        "name": "PrimitiveNode"
    },
    {
        "id": 1566,
        "name": "PrimitiveNode"
    },
    {
        "id": 1568,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1784,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1791,
        "name": "ControlNetLoaderAdvanced",
        "prompts": {
            "text": "controlnet11Models_pix2pix.safetensors"
        }
    },
    {
        "id": 1793,
        "name": "DiffControlNetLoaderAdvanced",
        "prompts": {
            "text": "diff_control_sd15_temporalnet_fp16.safetensors"
        }
    },
    {
        "id": 1795,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1796,
        "name": "EmptyLatentImage"
    },
    {
        "id": 1932,
        "name": "PrimitiveNode"
    },
    {
        "id": 1933,
        "name": "PrimitiveNode"
    },
    {
        "id": 1934,
        "name": "PrimitiveNode"
    },
    {
        "id": 1935,
        "name": "PrimitiveNode"
    },
    {
        "id": 1938,
        "name": "PrimitiveNode"
    },
    {
        "id": 1940,
        "name": "PrimitiveNode"
    },
    {
        "id": 1941,
        "name": "ScaledSoftControlNetWeights"
    },
    {
        "id": 1943,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1945,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 1946,
        "name": "IPAdapterModelLoader",
        "prompts": {
            "text": "ip-adapter-plus_sd15.bin"
        }
    },
    {
        "id": 1947,
        "name": "CLIPVisionLoader",
        "prompts": {
            "text": "SD1.5\\pytorch_model.bin"
        }
    },
    {
        "id": 1948,
        "name": "PrepImageForClipVision"
    },
    {
        "id": 1949,
        "name": "IPAdapterEncoder"
    },
    {
        "id": 1950,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1951,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 1972,
        "name": "LoadImage",
        "prompts": {
            "text": "2023_02_24__15_18_45_0.png"
        }
    },
    {
        "id": 1983,
        "name": "Separate Mask Components"
    },
    {
        "id": 1984,
        "name": "ImpactSimpleDetectorSEGS"
    },
    {
        "id": 1985,
        "name": "UltralyticsDetectorProvider",
        "prompts": {
            "text": "segm/person_yolov8s-seg.pt"
        }
    },
    {
        "id": 1986,
        "name": "SegsToCombinedMask"
    },
    {
        "id": 1987,
        "name": "MaskToImage"
    },
    {
        "id": 1988,
        "name": "Mask To Region"
    },
    {
        "id": 1989,
        "name": "ImpactSEGSRangeFilter"
    },
    {
        "id": 1990,
        "name": "Cut By Mask"
    },
    {
        "id": 1991,
        "name": "Cut By Mask"
    },
    {
        "id": 1992,
        "name": "SAMLoader",
        "prompts": {
            "text": "sam_vit_b_01ec64.pth"
        }
    },
    {
        "id": 1996,
        "name": "Paste By Mask",
        "prompts": {
            "text": "source_size"
        }
    },
    {
        "id": 1999,
        "name": "Change Channel Count"
    },
    {
        "id": 2000,
        "name": "Get Image Size"
    },
    {
        "id": 2001,
        "name": "OneFormer-COCO-SemSegPreprocessor"
    },
    {
        "id": 2002,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2003,
        "name": "Image Select Color"
    },
    {
        "id": 2004,
        "name": "Image To Mask"
    },
    {
        "id": 2005,
        "name": "ToBinaryMask"
    },
    {
        "id": 2006,
        "name": "MaskToImage"
    },
    {
        "id": 2007,
        "name": "PreviewImage"
    },
    {
        "id": 2008,
        "name": "Reroute"
    },
    {
        "id": 2009,
        "name": "Blur"
    },
    {
        "id": 2010,
        "name": "ImpactSimpleDetectorSEGS"
    },
    {
        "id": 2011,
        "name": "ImpactSEGSRangeFilter"
    },
    {
        "id": 2012,
        "name": "SegsToCombinedMask"
    },
    {
        "id": 2013,
        "name": "MaskToImage"
    },
    {
        "id": 2015,
        "name": "Mask Morphology"
    },
    {
        "id": 2016,
        "name": "Unary Mask Op"
    },
    {
        "id": 2019,
        "name": "Get Image Size"
    },
    {
        "id": 2020,
        "name": "Reroute"
    },
    {
        "id": 2021,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2022,
        "name": "AlphaChanelAddByMask"
    },
    {
        "id": 2027,
        "name": "Reroute"
    },
    {
        "id": 2028,
        "name": "Reroute"
    },
    {
        "id": 2030,
        "name": "PrimitiveNode"
    },
    {
        "id": 2031,
        "name": "PrimitiveNode"
    },
    {
        "id": 2032,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2041,
        "name": "Image To Mask"
    },
    {
        "id": 2047,
        "name": "Change Channel Count"
    },
    {
        "id": 2048,
        "name": "GrowMask"
    },
    {
        "id": 2049,
        "name": "Reroute"
    },
    {
        "id": 2050,
        "name": "Reroute"
    },
    {
        "id": 2052,
        "name": "Reroute"
    },
    {
        "id": 2053,
        "name": "Reroute"
    },
    {
        "id": 2054,
        "name": "PreviewImage"
    },
    {
        "id": 2055,
        "name": "PreviewImage"
    },
    {
        "id": 2056,
        "name": "Reroute"
    },
    {
        "id": 2057,
        "name": "Reroute"
    },
    {
        "id": 2058,
        "name": "Reroute"
    },
    {
        "id": 2059,
        "name": "Reroute"
    },
    {
        "id": 2060,
        "name": "Reroute"
    },
    {
        "id": 2062,
        "name": "Reroute"
    },
    {
        "id": 2066,
        "name": "Reroute"
    },
    {
        "id": 2067,
        "name": "Reroute"
    },
    {
        "id": 2068,
        "name": "Reroute"
    },
    {
        "id": 2069,
        "name": "PreviewImage"
    },
    {
        "id": 2071,
        "name": "Reroute"
    },
    {
        "id": 2073,
        "name": "Reroute"
    },
    {
        "id": 2076,
        "name": "PreviewImage"
    },
    {
        "id": 2077,
        "name": "Paste By Mask"
    },
    {
        "id": 2079,
        "name": "RebatchImages"
    },
    {
        "id": 2080,
        "name": "Reroute"
    },
    {
        "id": 2082,
        "name": "ImageScaleBy"
    },
    {
        "id": 2088,
        "name": "Change Channel Count"
    },
    {
        "id": 2089,
        "name": "Get Image Size"
    },
    {
        "id": 2090,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2091,
        "name": "Reroute"
    },
    {
        "id": 2092,
        "name": "VHS_VideoCombine"
    },
    {
        "id": 2095,
        "name": "Get Image Size"
    },
    {
        "id": 2097,
        "name": "EmptyLatentImage"
    },
    {
        "id": 2105,
        "name": "Reroute"
    },
    {
        "id": 2157,
        "name": "ImpactSimpleDetectorSEGS"
    },
    {
        "id": 2158,
        "name": "ImpactSEGSRangeFilter"
    },
    {
        "id": 2159,
        "name": "SegsToCombinedMask"
    },
    {
        "id": 2160,
        "name": "MaskToImage"
    },
    {
        "id": 2161,
        "name": "Mask Morphology"
    },
    {
        "id": 2162,
        "name": "Unary Mask Op"
    },
    {
        "id": 2163,
        "name": "Reroute"
    },
    {
        "id": 2164,
        "name": "Reroute"
    },
    {
        "id": 2166,
        "name": "UltralyticsDetectorProvider",
        "prompts": {
            "text": "bbox/face_yolov8n_v2.pt"
        }
    },
    {
        "id": 2178,
        "name": "PrimitiveNode"
    },
    {
        "id": 2180,
        "name": "PrimitiveNode"
    },
    {
        "id": 2181,
        "name": "RebatchImages"
    },
    {
        "id": 2186,
        "name": "Change Channel Count"
    },
    {
        "id": 2187,
        "name": "Mask To Region"
    },
    {
        "id": 2189,
        "name": "Cut By Mask"
    },
    {
        "id": 2190,
        "name": "Cut By Mask"
    },
    {
        "id": 2191,
        "name": "Separate Mask Components"
    },
    {
        "id": 2193,
        "name": "Reroute"
    },
    {
        "id": 2194,
        "name": "ImageScaleBy"
    },
    {
        "id": 2195,
        "name": "Change Channel Count"
    },
    {
        "id": 2196,
        "name": "Get Image Size"
    },
    {
        "id": 2197,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2198,
        "name": "Reroute"
    },
    {
        "id": 2199,
        "name": "Reroute"
    },
    {
        "id": 2200,
        "name": "Reroute"
    },
    {
        "id": 2206,
        "name": "Change Channel Count"
    },
    {
        "id": 2207,
        "name": "Change Channel Count"
    },
    {
        "id": 2208,
        "name": "Change Channel Count"
    },
    {
        "id": 2209,
        "name": "Blur"
    },
    {
        "id": 2210,
        "name": "Reroute"
    },
    {
        "id": 2211,
        "name": "Reroute"
    },
    {
        "id": 2212,
        "name": "Reroute"
    },
    {
        "id": 2221,
        "name": "Note",
        "prompts": {
            "text": "Animate diff settings - These settings are mirrored across both models\n\nNew V3 Model works amazing!\nhttps://github.com/guoyww/AnimateDiff\n\nV3 Motion lora goes in below Bypass if not using V3 or dont want to use it.. \n\nBase resolution is up to your vram and frames, i do 320x480 for base from the custom latent. Upscale 1.5 and 1.5. Can do more.\nFirst upscale is still batched so be careful not to go too big here.\n\nMotion model - Load the motion model here\nV2 Model - If you are using a V2 Model, check this box to true\nPE Scale - Speed of animation, can slow down jerky movement, but it's buggy, default 0 \nMotion Scale - how fast the animation. Some models like it low, some high, range of 0.8-1.2\nBeta Schedule - choose what you need labels are there\n\nContext Options\nContext length is how long the context will be. 16-32 work on V2 models, 24 for older. I used 16 for nearly all due to going higher, washing out the video background/setting.  But it stabilizes the subject a lot, so can be used to get motion data to later replace the background.\nContext stride - used to extend the context window. Not an expert, but\n  - 16 1 4 works well for 16\n  - 16 2 4 works well for 32\n  - 16 4 4 works well for 48\nThese can go up or down for stride, can go up to 8 from what I can tell.  Not much help after 6 though.\nClosed loop - tries to make a closed loop video... From what I can tell it does this all the time and this setting does nothing but take longer to make. But up to you if you use it.\n\nTo use this, right-click the group top and \"set group nodes to always\".  To disable, right-click the group top and select \"bypass group nodes\""
        }
    },
    {
        "id": 2230,
        "name": "Reroute"
    },
    {
        "id": 2231,
        "name": "Reroute"
    },
    {
        "id": 2232,
        "name": "Reroute"
    },
    {
        "id": 2235,
        "name": "Reroute"
    },
    {
        "id": 2236,
        "name": "Note",
        "prompts": {
            "text": "Ip adaptor settings \n\nThe image loaded here is loaded for all ip adaptor, and a face is cropped for the face enhance if enabled.  You can enable this at whatever steps.\n\nI prefer step 1 at 40-60% ip adaptor plus. Then 80, then 80, then on face 90. \n\nThis can copy a person in a photo and put them in your with your prompt to get an image/video, combined with reactor it's kinda creepy.\n*** be responsible.\n\n\nBypass Apply ip adaptor if not using\n\nConnect image or frames to prepare image\n\nLoading ipadaptor models here\n\nLoad a base image in at the bottom\n\nPrepare image \nUse this to sharpen or crop the base image\n\nEncode Image Lets you Add more image to the referance if you want.\n\n\n\nNoise is used to add noise to change your base image more.\n\nWeight can be anything from .1 to 2 i think.  0.6-8 is where i use it.  \n\nWeight type\nI find channel penalty to give sharper results, test them out yourself.\n\nStart and end at determines how many steps to apply the adaptor to in a percent. Currently, 12-step default if i do 0.5 for end at it will stop adapting the image at 6 steps.\n\nUnfold batch - this is used to use a batch of images for references, mostly used for animations. Example below Unfold the batch\n\nCan use a video (image frames of video) to import them here and send it to try to copy the video. \n\nSetting the strength/end steps with this method can copy a video motion but change things if you give it time at the end. \n\nCan add a cropped face if wanted for the face ipadaptor."
        }
    },
    {
        "id": 2237,
        "name": "VHS_LoadImagesPath"
    },
    {
        "id": 2238,
        "name": "Reroute"
    },
    {
        "id": 2239,
        "name": "Reroute"
    },
    {
        "id": 2240,
        "name": "ImpactSimpleDetectorSEGS"
    },
    {
        "id": 2241,
        "name": "ImpactSEGSRangeFilter"
    },
    {
        "id": 2242,
        "name": "SegsToCombinedMask"
    },
    {
        "id": 2243,
        "name": "MaskToImage"
    },
    {
        "id": 2245,
        "name": "Unary Mask Op"
    },
    {
        "id": 2246,
        "name": "PreviewImage"
    },
    {
        "id": 2247,
        "name": "Reroute"
    },
    {
        "id": 2248,
        "name": "Reroute"
    },
    {
        "id": 2249,
        "name": "Reroute"
    },
    {
        "id": 2250,
        "name": "Reroute"
    },
    {
        "id": 2257,
        "name": "PrimitiveNode"
    },
    {
        "id": 2280,
        "name": "LatentCrop"
    },
    {
        "id": 2286,
        "name": "PrimitiveNode"
    },
    {
        "id": 2287,
        "name": "PrimitiveNode"
    },
    {
        "id": 2288,
        "name": "PrimitiveNode"
    },
    {
        "id": 2289,
        "name": "PrimitiveNode"
    },
    {
        "id": 2301,
        "name": "PreviewImage"
    },
    {
        "id": 2327,
        "name": "ReActorFaceSwap",
        "prompts": {
            "text": "inswapper_128.onnx",
            "text_2": "retinaface_resnet50"
        }
    },
    {
        "id": 2330,
        "name": "FILM VFI",
        "prompts": {
            "text": "film_net_fp32.pt"
        }
    },
    {
        "id": 2349,
        "name": "Reroute"
    },
    {
        "id": 2353,
        "name": "Reroute"
    },
    {
        "id": 2354,
        "name": "Reroute"
    },
    {
        "id": 2355,
        "name": "VAEEncode"
    },
    {
        "id": 2357,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2363,
        "name": "PrimitiveNode"
    },
    {
        "id": 2364,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2366,
        "name": "Get Image Size"
    },
    {
        "id": 2367,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2368,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2369,
        "name": "Image To Mask"
    },
    {
        "id": 2370,
        "name": "AlphaChanelAddByMask"
    },
    {
        "id": 2371,
        "name": "Paste By Mask",
        "prompts": {
            "text": "source_size"
        }
    },
    {
        "id": 2372,
        "name": "PreviewImage"
    },
    {
        "id": 2373,
        "name": "VHS_VideoCombine"
    },
    {
        "id": 2376,
        "name": "KSamplerAdvanced",
        "prompts": {
            "text": "sgm_uniform"
        }
    },
    {
        "id": 2377,
        "name": "VAEDecode"
    },
    {
        "id": 2378,
        "name": "KSamplerAdvanced",
        "prompts": {
            "text": "sgm_uniform"
        }
    },
    {
        "id": 2379,
        "name": "VAEDecode"
    },
    {
        "id": 2383,
        "name": "Reroute"
    },
    {
        "id": 2384,
        "name": "Reroute"
    },
    {
        "id": 2385,
        "name": "Reroute"
    },
    {
        "id": 2386,
        "name": "Reroute"
    },
    {
        "id": 2387,
        "name": "Reroute"
    },
    {
        "id": 2388,
        "name": "Reroute"
    },
    {
        "id": 2389,
        "name": "Reroute"
    },
    {
        "id": 2390,
        "name": "Reroute"
    },
    {
        "id": 2391,
        "name": "KSamplerAdvanced",
        "prompts": {
            "text": "sgm_uniform"
        }
    },
    {
        "id": 2392,
        "name": "VAEDecode"
    },
    {
        "id": 2393,
        "name": "Reroute"
    },
    {
        "id": 2396,
        "name": "KSamplerAdvanced",
        "prompts": {
            "text": "sgm_uniform"
        }
    },
    {
        "id": 2397,
        "name": "CLIPTextEncode"
    },
    {
        "id": 2398,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, lace, frills, jewellery"
        }
    },
    {
        "id": 2399,
        "name": "VAEDecode"
    },
    {
        "id": 2400,
        "name": "Reroute"
    },
    {
        "id": 2401,
        "name": "Reroute"
    },
    {
        "id": 2403,
        "name": "Reroute"
    },
    {
        "id": 2404,
        "name": "Reroute"
    },
    {
        "id": 2407,
        "name": "workflow/Bus"
    },
    {
        "id": 2409,
        "name": "workflow/Bus 2"
    },
    {
        "id": 2410,
        "name": "Reroute"
    },
    {
        "id": 2411,
        "name": "Reroute"
    },
    {
        "id": 2412,
        "name": "Reroute"
    },
    {
        "id": 2413,
        "name": "Reroute"
    },
    {
        "id": 2414,
        "name": "Reroute"
    },
    {
        "id": 2415,
        "name": "Reroute"
    },
    {
        "id": 2416,
        "name": "Reroute"
    },
    {
        "id": 2417,
        "name": "Reroute"
    },
    {
        "id": 2418,
        "name": "Reroute"
    },
    {
        "id": 2419,
        "name": "Reroute"
    },
    {
        "id": 2420,
        "name": "Reroute"
    },
    {
        "id": 2421,
        "name": "Reroute"
    },
    {
        "id": 2422,
        "name": "Reroute"
    },
    {
        "id": 2423,
        "name": "Reroute"
    },
    {
        "id": 2424,
        "name": "Reroute"
    },
    {
        "id": 2425,
        "name": "Reroute"
    },
    {
        "id": 2426,
        "name": "Reroute"
    },
    {
        "id": 2427,
        "name": "Reroute"
    },
    {
        "id": 2428,
        "name": "Reroute"
    },
    {
        "id": 2429,
        "name": "Reroute"
    },
    {
        "id": 2430,
        "name": "Reroute"
    },
    {
        "id": 2432,
        "name": "Reroute"
    },
    {
        "id": 2433,
        "name": "Reroute"
    },
    {
        "id": 2434,
        "name": "Reroute"
    },
    {
        "id": 2435,
        "name": "Reroute"
    },
    {
        "id": 2436,
        "name": "Reroute"
    },
    {
        "id": 2437,
        "name": "Reroute"
    },
    {
        "id": 2438,
        "name": "Reroute"
    },
    {
        "id": 2439,
        "name": "Reroute"
    },
    {
        "id": 2440,
        "name": "Reroute"
    },
    {
        "id": 2441,
        "name": "Reroute"
    },
    {
        "id": 2442,
        "name": "Reroute"
    },
    {
        "id": 2443,
        "name": "Reroute"
    },
    {
        "id": 2444,
        "name": "Reroute"
    },
    {
        "id": 2445,
        "name": "Reroute"
    },
    {
        "id": 2446,
        "name": "Reroute"
    },
    {
        "id": 2447,
        "name": "Reroute"
    },
    {
        "id": 2448,
        "name": "Reroute"
    },
    {
        "id": 2449,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2450,
        "name": "Reroute"
    },
    {
        "id": 2451,
        "name": "PrimitiveNode"
    },
    {
        "id": 2452,
        "name": "PrimitiveNode",
        "prompts": {
            "text": "Asian, lace, frills, jewellery"
        }
    },
    {
        "id": 2453,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Asian, lace, frills, jewellery"
        }
    },
    {
        "id": 2454,
        "name": "CLIPTextEncode"
    },
    {
        "id": 2455,
        "name": "Reroute"
    },
    {
        "id": 2456,
        "name": "Reroute"
    },
    {
        "id": 2457,
        "name": "Reroute"
    },
    {
        "id": 2458,
        "name": "Reroute"
    },
    {
        "id": 2459,
        "name": "Reroute"
    },
    {
        "id": 2460,
        "name": "Reroute"
    },
    {
        "id": 2461,
        "name": "Reroute"
    },
    {
        "id": 2462,
        "name": "Reroute"
    },
    {
        "id": 2463,
        "name": "Reroute"
    },
    {
        "id": 2464,
        "name": "Reroute"
    },
    {
        "id": 2465,
        "name": "Reroute"
    },
    {
        "id": 2468,
        "name": "KSamplerAdvanced",
        "prompts": {
            "text": "sgm_uniform"
        }
    },
    {
        "id": 2469,
        "name": "ImageSelector"
    },
    {
        "id": 2470,
        "name": "VAEEncode"
    },
    {
        "id": 2471,
        "name": "VAEDecode"
    },
    {
        "id": 2473,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2474,
        "name": "PrimitiveNode"
    },
    {
        "id": 2476,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2483,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2484,
        "name": "Reroute"
    },
    {
        "id": 2485,
        "name": "Reroute"
    },
    {
        "id": 2486,
        "name": "Reroute"
    },
    {
        "id": 2487,
        "name": "Reroute"
    },
    {
        "id": 2488,
        "name": "Reroute"
    },
    {
        "id": 2495,
        "name": "RIFE VFI"
    },
    {
        "id": 2497,
        "name": "CropFace"
    },
    {
        "id": 2547,
        "name": "Change Channel Count"
    },
    {
        "id": 2548,
        "name": "PreviewImage"
    },
    {
        "id": 2550,
        "name": "Reroute"
    },
    {
        "id": 2553,
        "name": "Reroute"
    },
    {
        "id": 2554,
        "name": "LoadImage",
        "prompts": {
            "text": "2023_02_24__15_18_45_0 (1).png"
        }
    },
    {
        "id": 2557,
        "name": "Reroute"
    },
    {
        "id": 2558,
        "name": "Reroute"
    },
    {
        "id": 2560,
        "name": "Reroute"
    },
    {
        "id": 2562,
        "name": "Reroute"
    },
    {
        "id": 2563,
        "name": "Change Channel Count"
    },
    {
        "id": 2564,
        "name": "Note",
        "prompts": {
            "text": "Detection settings\n\nThis uses bbox from impact pack simple detectors to make box masks of face and body,  then uses seg or sam to mask the object.  This allows the mask to not need to be perfect to work.  \n\n2 big new options are the Min size of the masks you allow the workflow to work on.  This allows you to pick out only the main subjects and leave the others.  These settings are to determine by and the mask size for both face and body. \n\nI prefer width as determine, but others can work. \nYou choose the size of the dimension that you choose.  Any masks smaller than the Mask size in (width/height/area) are ignored.  The numbers depend on how large your images/videos are.\nWith this you don't need to enhance background objects, like photo frames, or people out of frame but detected. Defaults are a bit small for video\n\nCoco and Sam masking options for masks.  Sam is very accurate and preferred, but sometimes I have no idea what it's trying to detect, so Coco is a good second option if sams masks are wonky.  Disable the group that you are not using. \n\nChoose the bbox detector / seg for person and face. \n\nIMO\nyolovn8n2 v2 works best for face \nperson_yolov8s-seg works best for body\n\nOthers can work too, if you don't want to detect faces, you can change that one to any.  \n\nThe body needs to stay as body if you are using coco masks.  If using sam you can use any detection there that you can get to work, hair, clothes, etc.\n\nBbox Threshold - lower if nothing detected, and raise if too much is.\nCoco can use any resolution mask you want, lower is less accurate, but faster.\n\nYou can look at the masks and decide what one to use\n\nSam is off by default for bodies, it uses seg masks connect the sam loader to the detecter if you want sam."
        }
    },
    {
        "id": 2565,
        "name": "Note",
        "prompts": {
            "text": "Upscaling bodies options Warning all controlnets are for 1.5, you need a 1.5 model for these as it needs tile at least\n\nThis cuts out bodies masked above and upscales/enhances them, then pastes them back to the image.\n\n2 model options like before\nConnect Model/VAE/POS/NEG of the model you would like to use.\n\nSteps can be anything really. start 0-6 end 8-16?  anything really, i use 0-8 or 0-12.  Adding size in the upscale before this helps more than more steps imo.\n\n2 Options for the latent to use. IMPORTANT - use Image latent if multiple people will be being enhanced.  Masks need it. 1 person works fine with empty.\nEmpty - This is an empty latent (batch) that works because of the control nets.  Helps stop image burning from using strong control nets.  However, it only works with 1 person, multiple masks wont work this way,\nImage - This is the images passed in from the previous step. - can use this if you do not want to 100% denoise and start the steps at 2-6.  This is faster, but some models burn the images\n\nUpscale option here. Only upscales for the fixing and then downsamples. 1.2-2 is ok, it's not needed, but small bases (animations) can benefit.\n\nPrompt should enforce colours used in previous prompts\n\n4 Control nets setup\n\nTile and pix to pix are used for images to hold the body and colours.\nTemporal net is used for animations if you want. Not 100% needed I think\nLine art is used for animations to hold consistency. Can use hed if you like, just connect the HED to the used node and change the line art control model.\nDon't go too high on line art res, it grabs random stuff that causes inconsistency.  Little bumps in the original video become more pronounced.\n\nFor videos I use all 4 controlnets at default settings currently\nfor videos, you can start steps at 2-4 if too many changes or flicker\n\nUsing negatives here is important.  This likes to put nipples on things.  It's obsessed on putting nipple pokies on everyone.... Negative out anything that shows up that you don't want."
        }
    },
    {
        "id": 2566,
        "name": "Note",
        "prompts": {
            "text": "Person Separation - you can bypass this group if only one person or many people touching or your not cutting out the people below.\n\nTanks more memory to do this\nThis works, pretty sure even on batches/animations\nIt separates the bboxs into separate images\n\nThis \"can\" separate the real masks to allow full separation of people instead of bboxes by dragging a mask from the left to the box input.  It works only if it's a perfect mask.  Otherwise, you end up overprocessing a lot. \n\nBboxes are fine for 99% of tasks.  But you have the option\n"
        }
    },
    {
        "id": 2567,
        "name": "Note",
        "prompts": {
            "text": "face Cutting - Blur/padding help with blending back images.\n\nPadding can help give more room for context, 10-20 is good. Takes longer but good results from it\nBlur to help with blending.  "
        }
    },
    {
        "id": 2568,
        "name": "Note",
        "prompts": {
            "text": "Face Detection settings\n\nBbox Threshold - lower if nothing detected, and raise if too much is.\n\nIf boxes are here that are not things you want to enhance, stop and change the size in the options to something larger or smaller.\n\nMasking off faces of large videos takes alot of video memory."
        }
    },
    {
        "id": 2570,
        "name": "Note",
        "prompts": {
            "text": "Face Separation\n\nThis works, pretty sure even on batches/animations\nIt separates the bboxs into separate images\n\nDownscale helps as separate masks takes a long time, and they are boxes we are down scaling."
        }
    },
    {
        "id": 2572,
        "name": "Note",
        "prompts": {
            "text": "Upscaling face options - Important this will error if no faces are found in any of the images in the batch/video\n\nThis cuts out faces masked above and upscales/enhances them, then pastes them back to the image.\n\n2 model options like before\nConnect Model/VAE/POS/NEG of the model you would like to use.\n\nChoose the size to make the faces for to enhance.  768 works well, as does 512.\n\nPrompt should enforce colours used in previous prompts and can change eye or lip colour.\n1 Control net\nTile used to hold the face and colours.\n\nIts kinda cool how it goes through each person, one buy one doing each frame in videos and keeps most consistancy."
        }
    },
    {
        "id": 2573,
        "name": "Note",
        "prompts": {
            "text": "Face replacement\n\nThe node to the left is default disabled, its not needed most of the time if you have a photo already of a face you want to emulate.\n\nUseful for videos.  Bypass both the left and below groups to pass through and not do face replacement but still do frame interpolation next\n\nGroup to the right chooses 1 images from a image/batch and upscales it to use as a base for reactor face swap. \n\nif there is 2+ people in the photo or video, choose the one frame/batchnumber you want to use to crop faces from.  It will crop out all faces from that one frame/image and use them all in reactor.  You need to change reactor to accept multiple faces.\n\nCan set size of the face to use for reactor\nImage selector is used to select the image from a batch(frames) set this to 1 if only one image.\n\nUse model/vae from above to change model, the pos and neg are here to use.\n\nProblem with this is it does not respect the same limits given above, so you may end up swapping out a face in a painting...."
        }
    },
    {
        "id": 2574,
        "name": "Note",
        "prompts": {
            "text": "Face replacement choices, \n\nDefault brings in the above faces from the image/video\nLoaded brings in your image from the load here\nPicks brings in the selectors choices\n\nSource faces index and input faces index can be 0 for 1 face\n0,1 for two faces, 0,1,2 for three.\n\nYou need to make sure you send in the same number of faces you want to swap\n\nCan swap female or male."
        }
    },
    {
        "id": 2575,
        "name": "Note",
        "prompts": {
            "text": "Frame interpolation raises 12 fps diff videos to 24. Or more.\n\nThis should be disabled unless you are using animate diff for animations.\n\nFilm VFI is my favourite but takes longest, rife is fast and decent quality.\nFrame Interpolator works well, Many other options from that node group.\n\nSave video is saved output\\n-suite\\videos\n\nCan save both video and frames\n\nIf using Film or Rife, set fps to the final fps you're aiming for. 24 for 2x, 36 for 3, 48 for embedding:zend4y4, \n\nIf using frame interpolator, set fps to 12 as it will change it when it does the interpolation\n"
        }
    },
    {
        "id": 2576,
        "name": "Note",
        "prompts": {
            "text": "Can Bypass this group if you want to process the entire Photo again in this step, If it's on it cuts out the people and repastes them at the end.  It can save time when the person is smaller in the photo or video than the full image.\n\nyou can do this step even without the person separation above when its one person or more it will just combine all masks\n\nConnect the masks you want to use from the left to the masks here\nSAM is default, but coco can be used"
        }
    },
    {
        "id": 2577,
        "name": "Note",
        "prompts": {
            "text": "Ip adaptor settings Bypass Apply ip adaptor if not using\n\ncan use the loaded image or the frames/images from the last generation. If using the frames check the option for unfold batch.\n\nPrepare image \nUse this to sharpen or crop the base image\n\nEncode Image Lets you Add more image to the referance if you want.\n\nNoise is used to add noise to change your base image more.\n\nWeight can be anything from .1 to 2 i think.  0.6-8 is where i use it.  \n\nWeight type\nI find channel penalty to give sharper results, test them out yourself.\n\nStart and end at determines how many steps to apply the adaptor to in a percent. Currently, 12-step default if i do 0.5 for end at it will stop adapting the image at 6 steps.\n\nMask can be used to only apply the adaptor to the person. on the last one."
        }
    },
    {
        "id": 2579,
        "name": "Note",
        "prompts": {
            "text": "Welcome.  Hopefully this becomes than picture perfect \n\nBeta 2 - Think most bugs gone, runs fairly smooth.  If memory error and using fixed seed just try again.  most times it works\n\nThis is a huge workflow, and I don't know how much memory it takes for all the options.  12 GB seems working for everything I have tried, so I need testers.\n\nThis was a work in progress for months now and has been a thorn in my side figuring out how to make batches work.  Turns out I just needed comfy UI to add a rebatch images node. \n\nFeel free to play with any settings, mine are not set in stone. If anything does not work, let me know and I will try to fix it.\n\nBecause of its size, the more things you enable in this workflow, the more memory you will probably need.  Also, when you press queue, it can take a while to sort through hundreds of nodes to find out where things changed if you are using a fixed seed and changing something in the workflow. After a few videos, I reset the UI.  It's a lot of memory, and I think I'm getting close to the max number of nodes in 1 flow. (think this is fixed)\n\nThere is a lot here and I tried to make notes for all.  \n\nNew in this version\n\nFull batch processing, hence allowing animate diff to work\nIp adaptor integration.\nCropping initial images\nFull control net support\nReactor face swapping\nFrame Interpolation\nMany extra model options\nLCM\n2 masking options.\nControl of masks used, no more background objects\nBetter Person separation.\n\nBack and better\nFace and body enhancing working for both batches of images and video through animate diff.  400 seconds 16frame 960x1440 video on my 3060 starting from 320x480\nMore efficient masking with less unneeded masking tasks. Might be faster not sure really."
        }
    },
    {
        "id": 2580,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2581,
        "name": "ControlNetLoaderAdvanced",
        "prompts": {
            "text": "control_v11p_sd15_lineart_fp16.safetensors"
        }
    },
    {
        "id": 2582,
        "name": "LineArtPreprocessor"
    },
    {
        "id": 2583,
        "name": "Get Image Size"
    },
    {
        "id": 2584,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2585,
        "name": "ACN_AdvancedControlNetApply"
    },
    {
        "id": 2586,
        "name": "PrimitiveNode"
    },
    {
        "id": 2587,
        "name": "PrimitiveNode"
    },
    {
        "id": 2588,
        "name": "PrimitiveNode"
    },
    {
        "id": 2589,
        "name": "Reroute"
    },
    {
        "id": 2590,
        "name": "Note",
        "prompts": {
            "text": "First upscale pass below, this is a batch process\n\nModel choice here same as before\nmodel/vae/pos/neg connect from your choice.\n\nSteps should anywhere from start at 4 to end at 12 CFG 1.3-2.2\nlcm sgm_uniform try others if you want\n\n3 options for the latent to use\n\nEmpty - This is an empty latent (batch) that works because of the control nets.  Helps stop image burning from using strong control nets.\nImage - This is the images passed in from the previous step.\nLatent - This is the latent from the previous step\n\nLatent or image is best here, empty only works with tile control net. and only if only 1 person in the video/photo\n"
        }
    },
    {
        "id": 2591,
        "name": "Note",
        "prompts": {
            "text": "Base Generation\n\nUse this as a normal text to image prompt, don't go too long if an animation, shorter is better. When prompting, animations don't repeat.  Blond hair, brown hair... will mix. 1 colour is best, if you mention an object like clothing only do it once.  Beach sandals, 1girl, funny face, detailed eyes, pink sandals... mention things ONCE with detail.  Pink beach sandals with a flower works, the other blends. \n\nChoice of model 1 or 2, Model/VAE/Pos/Neg of your choice need to be connected to the matching nodes to the right of them of your choice. Default is model 1\n\nBatching works for images or animations\nSizes are the left and right of the sampler, or use custom.  320x480 or reverse works well for animations"
        }
    },
    {
        "id": 2592,
        "name": "PreviewImage"
    },
    {
        "id": 2605,
        "name": "Preview Chooser",
        "prompts": {
            "text": "Only pause if batch"
        }
    },
    {
        "id": 2608,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2609,
        "name": "ImagePadForOutpaint"
    },
    {
        "id": 2612,
        "name": "Paste By Mask",
        "prompts": {
            "text": "source_size"
        }
    },
    {
        "id": 2614,
        "name": "MaskToImage"
    },
    {
        "id": 2617,
        "name": "ImagePadForOutpaint"
    },
    {
        "id": 2619,
        "name": "Paste By Mask",
        "prompts": {
            "text": "source_size"
        }
    },
    {
        "id": 2620,
        "name": "MaskToImage"
    },
    {
        "id": 2621,
        "name": "Reroute"
    },
    {
        "id": 2625,
        "name": "Reroute"
    },
    {
        "id": 2626,
        "name": "Reroute"
    },
    {
        "id": 2630,
        "name": "ImageSelector"
    },
    {
        "id": 2631,
        "name": "ImageSelector"
    },
    {
        "id": 2632,
        "name": "ImageSelector"
    },
    {
        "id": 2636,
        "name": "Reroute"
    },
    {
        "id": 2637,
        "name": "ImageScale",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2639,
        "name": "ImageBatch"
    },
    {
        "id": 2650,
        "name": "Change Channel Count"
    },
    {
        "id": 2660,
        "name": "Paste By Mask"
    },
    {
        "id": 2661,
        "name": "PreviewImage"
    },
    {
        "id": 2662,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2663,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2664,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2665,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2666,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2667,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2668,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2670,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2671,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2672,
        "name": "PrimitiveNode"
    },
    {
        "id": 2673,
        "name": "Change Channel Count"
    },
    {
        "id": 2674,
        "name": "Change Channel Count"
    },
    {
        "id": 2675,
        "name": "Change Channel Count"
    },
    {
        "id": 2676,
        "name": "Change Channel Count"
    },
    {
        "id": 2677,
        "name": "Change Channel Count"
    },
    {
        "id": 2678,
        "name": "Change Channel Count"
    },
    {
        "id": 2679,
        "name": "Change Channel Count"
    },
    {
        "id": 2680,
        "name": "Change Channel Count"
    },
    {
        "id": 2681,
        "name": "Change Channel Count"
    },
    {
        "id": 2682,
        "name": "Reroute"
    },
    {
        "id": 2683,
        "name": "Change Channel Count"
    },
    {
        "id": 2685,
        "name": "CropFace",
        "prompts": {
            "text": "retinaface_resnet50"
        }
    },
    {
        "id": 2689,
        "name": "ImageScaleBy",
        "prompts": {
            "text": "nearest-exact"
        }
    },
    {
        "id": 2690,
        "name": "PreviewImage"
    },
    {
        "id": 2691,
        "name": "Note",
        "prompts": {
            "text": "Face Chooser this shows you the faces from the left created mixed with the loaded image you provide Disable this whole step if only one face is being replaced\n\nReplacing faces occurs left to right, top to bottom\nSet count to the number of faces your selecting\nClick the faces in the order you want them replaced, the chooser will send the images to below in order clicked to combine them into 1 image for reactor.\n\nBypass 2 face/3 face when you only are replacing one, the chooser will show you all faces from the face enhance step, and the faces from load/enhance steps\n"
        }
    },
    {
        "id": 2692,
        "name": "ImageBatch"
    },
    {
        "id": 2693,
        "name": "FrameInterpolator"
    },
    {
        "id": 2695,
        "name": "SetMetadataForSaveVideo"
    },
    {
        "id": 2700,
        "name": "LoraLoader",
        "prompts": {
            "text": "v3_sd15_adapter.ckpt"
        }
    },
    {
        "id": 2702,
        "name": "LoraLoader",
        "prompts": {
            "text": "v3_sd15_adapter.ckpt"
        }
    },
    {
        "id": 2706,
        "name": "HEDPreprocessor"
    },
    {
        "id": 2707,
        "name": "Reroute"
    },
    {
        "id": 2709,
        "name": "Note",
        "prompts": {
            "text": "Loading an image can be too large to crop face.  \n\nCan downscale the input image to properly crop the face,\nthen you can upscale the face cutout to 1024x1024."
        }
    },
    {
        "id": 2713,
        "name": "Reroute"
    },
    {
        "id": 2714,
        "name": "Reroute"
    },
    {
        "id": 2715,
        "name": "Reroute"
    },
    {
        "id": 2716,
        "name": "Reroute"
    },
    {
        "id": 2717,
        "name": "RebatchImages"
    },
    {
        "id": 2719,
        "name": "Reroute"
    },
    {
        "id": 2720,
        "name": "Reroute"
    },
    {
        "id": 2721,
        "name": "Reroute"
    },
    {
        "id": 2722,
        "name": "Reroute"
    },
    {
        "id": 2723,
        "name": "RebatchImages"
    },
    {
        "id": 2724,
        "name": "Change Channel Count"
    },
    {
        "id": 2725,
        "name": "VHS_VideoCombine"
    },
    {
        "id": 2728,
        "name": "Note",
        "prompts": {
            "text": "Set group nodes to never\nto disable"
        }
    },
    {
        "id": 2729,
        "name": "Note",
        "prompts": {
            "text": "Set group to \"Bypass Group Nodes\" to disable"
        }
    },
    {
        "id": 2730,
        "name": "Note",
        "prompts": {
            "text": "Set group nodes to never\nto disable"
        }
    },
    {
        "id": 2731,
        "name": "Note",
        "prompts": {
            "text": "Set group nodes to never\nto disable"
        }
    },
    {
        "id": 2737,
        "name": "FaceRestoreWithModel",
        "prompts": {
            "text": "retinaface_resnet50"
        }
    },
    {
        "id": 2738,
        "name": "FaceRestoreModelLoader",
        "prompts": {
            "text": "codeformer.pth"
        }
    },
    {
        "id": 2739,
        "name": "Note",
        "prompts": {
            "text": "Face restore option if you are not using reactor, or it's bugging out with the workflow. "
        }
    },
    {
        "id": 2740,
        "name": "EmptyLatentImage"
    },
    {
        "id": 2741,
        "name": "Reroute"
    },
    {
        "id": 2742,
        "name": "EmptyLatentImage"
    },
    {
        "id": 2743,
        "name": "Reroute"
    },
    {
        "id": 2744,
        "name": "EmptyLatentImage"
    },
    {
        "id": 2745,
        "name": "EmptyLatentImage"
    },
    {
        "id": 2746,
        "name": "Reroute"
    },
    {
        "id": 2747,
        "name": "Reroute"
    },
    {
        "id": 2748,
        "name": "Note",
        "prompts": {
            "text": "Portrait Aspects"
        }
    },
    {
        "id": 2749,
        "name": "Note",
        "prompts": {
            "text": "Widescreen Aspects"
        }
    },
    {
        "id": 2751,
        "name": "Reroute"
    },
    {
        "id": 2755,
        "name": "RebatchImages"
    },
    {
        "id": 2757,
        "name": "Note",
        "prompts": {
            "text": "connect off when you have disabled above\n\nConnect on to when you have the above cutting stage enabled."
        }
    },
    {
        "id": 2761,
        "name": "Reroute"
    },
    {
        "id": 2762,
        "name": "Reroute"
    },
    {
        "id": 2763,
        "name": "Reroute"
    },
    {
        "id": 2764,
        "name": "Reroute"
    },
    {
        "id": 2766,
        "name": "Reroute"
    },
    {
        "id": 2767,
        "name": "ImageListToImageBatch"
    },
    {
        "id": 2768,
        "name": "Note",
        "prompts": {
            "text": "You can right-click and set group nodes to never for the upscales to hold the generation at that step."
        }
    },
    {
        "id": 2769,
        "name": "Note",
        "prompts": {
            "text": "You can right-click and set group nodes to never for the upscales to hold the generation at that step."
        }
    },
    {
        "id": 2774,
        "name": "PrepImageForClipVision"
    },
    {
        "id": 2776,
        "name": "IPAdapterEncoder"
    },
    {
        "id": 2777,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 2780,
        "name": "IPAdapterApplyEncoded",
        "prompts": {
            "text": "channel penalty"
        }
    },
    {
        "id": 2781,
        "name": "Reroute"
    },
    {
        "id": 2782,
        "name": "Reroute"
    },
    {
        "id": 2784,
        "name": "Reroute"
    },
    {
        "id": 2787,
        "name": "CropFace",
        "prompts": {
            "text": "retinaface_resnet50"
        }
    },
    {
        "id": 2788,
        "name": "IPAdapterModelLoader",
        "prompts": {
            "text": "ip-adapter-plus-face_sd15.bin"
        }
    }
]