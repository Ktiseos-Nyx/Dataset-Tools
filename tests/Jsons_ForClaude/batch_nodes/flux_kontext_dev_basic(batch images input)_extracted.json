[
    {
        "id": 5,
        "name": "Step 3 - Prompt"
    },
    {
        "id": 6,
        "name": "CLIPTextEncode",
        "prompts": {
            "text": "Using this elegant style, create a portrait of a swan wearing a pearl tiara and lace collar, maintaining the same refined quality and soft color tones."
        }
    },
    {
        "id": 7,
        "name": "Step 1- Load models"
    },
    {
        "id": 8,
        "name": "Step 2 - Upload images"
    },
    {
        "id": 10,
        "name": "Conditioning"
    },
    {
        "id": 12,
        "name": "Original"
    },
    {
        "id": 31,
        "name": "KSampler"
    },
    {
        "id": 35,
        "name": "FluxGuidance"
    },
    {
        "id": 135,
        "name": "ConditioningZeroOut"
    },
    {
        "id": 136,
        "name": "SaveImage"
    },
    {
        "id": 178,
        "name": "MarkdownNote",
        "prompts": {
            "text": "[English] In addition to using **Image Stitch** to combine two images at a time, you can also encode individual images, then concatenate multiple latent conditions using the **ReferenceLatent** node, thus achieving the purpose of referencing multiple images. You can use the **EmptySD3LatentImage** node on the right to connect to **KSamper** and customize the size of the **latent_image**.\n\n[\u4e2d\u6587] \u9664\u4e86\u4f7f\u7528 **Image Stitch** \u5c06\u4e24\u4e2a\u4e24\u4e2a\u56fe\u50cf\u62fc\u5408\u4e4b\u5916\uff0c\u4f60\u540c\u6837\u53ef\u4ee5\u5c06\u5355\u72ec\u7684\u56fe\u50cf encode \u4e4b\u540e\uff0c\u5c06\u591a\u4e2a latent \u6761\u4ef6\u4f7f\u7528 **ReferenceLatent** \u8282\u70b9\u4e32\u8054\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u5f20\u56fe\u50cf\u53c2\u8003\u7684\u76ee\u7684\u3002\u53ef\u4ee5\u4f7f\u7528\u53f3\u8fb9\u7684 **EmptySD3LatentImage** \u8282\u70b9\u8fde\u63a5\u5230 **KSamper**\u6765\u81ea\u5b9a\u4e49 **latent_image** \u7684\u5c3a\u5bf8"
        }
    },
    {
        "id": 180,
        "name": "MarkdownNote",
        "prompts": {
            "text": "[English]\nWe have added an **Edit** button to the **Selection Toolbox** of the node for **FLUX.1 Kontext Image Edit** support. When clicked, it quickly adds a **FLUX.1 Kontext Image Edit** group node to the Latent output of your current workflow. This enables an interactive editing experience where you can:\n\n- Create multiple editing iterations, each preserved as a separate node\n- Easily branch off from any previous edit point to explore different creative directions\n- Return to any earlier version and start a new editing branch\n- Modify parameters in earlier nodes and automatically update all downstream edits\n- Execute or re-execute any branch of edits at any time\n- When you want to maintain the effect of the corresponding branch, please set the seed of the corresponding group node to fixed.\n\n\nThis workflow mirrors the iterative nature of LLM conversations, but with the added advantage of visual editing and the ability to maintain multiple parallel editing paths.\n\n---\n\n[\u4e2d\u6587]\n\u6211\u4eec\u4e3a **FLUX.1 Kontext Image Edit** \u7684\u76f8\u5173\u652f\u6301\u5728\u8282\u70b9\u7684**\u9009\u62e9\u5de5\u5177\u7bb1**\u4e0a\u65b0\u589e\u4e86\u4e00\u4e2a**\u7f16\u8f91**\u6309\u94ae\u3002\u70b9\u51fb\u540e\uff0c\u7cfb\u7edf\u4f1a\u5728\u5f53\u524d\u5de5\u4f5c\u6d41\u7684 Latent \u8f93\u51fa\u4e0a\u5feb\u901f\u6dfb\u52a0\u4e00\u4e2a **FLUX.1 Kontext Image Edit** \u7684\u7ec4\u8282\u70b9\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5e26\u6765\u4e86\u7075\u6d3b\u7684\u4ea4\u4e92\u5f0f\u7f16\u8f91\u4f53\u9a8c\uff1a\n\n- \u521b\u5efa\u591a\u4e2a\u7f16\u8f91\u8fed\u4ee3\uff0c\u6bcf\u6b21\u7f16\u8f91\u90fd\u4f1a\u4fdd\u5b58\u4e3a\u72ec\u7acb\u8282\u70b9\n- \u53ef\u4ee5\u4ece\u4efb\u4f55\u4e4b\u524d\u7684\u7f16\u8f91\u70b9\u5206\u652f\u51fa\u65b0\u7684\u521b\u4f5c\u65b9\u5411\n- \u968f\u65f6\u8fd4\u56de\u5230\u65e9\u671f\u7248\u672c\u5e76\u5f00\u59cb\u65b0\u7684\u7f16\u8f91\u5206\u652f\n- \u4fee\u6539\u65e9\u671f\u8282\u70b9\u7684\u53c2\u6570\uff0c\u81ea\u52a8\u66f4\u65b0\u6240\u6709\u4e0b\u6e38\u7f16\u8f91\n- \u53ef\u4ee5\u968f\u65f6\u6267\u884c\u6216\u91cd\u65b0\u6267\u884c\u4efb\u4f55\u7f16\u8f91\u5206\u652f\n- \u60f3\u8981\u56fa\u5b9a\u5bf9\u5e94\u5206\u652f\u6548\u679c\u65f6\uff0c\u8bf7\u5c06\u5bf9\u5e94\u7684 seed \u8bbe\u7f6e\u4e3a fixed\n\n\u8fd9\u79cd\u5de5\u4f5c\u6d41\u7a0b\u7c7b\u4f3c\u4e8e LLM \u5bf9\u8bdd\u7684\u8fed\u4ee3\u7279\u6027\uff0c\u4f46\u589e\u52a0\u4e86\u89c6\u89c9\u7f16\u8f91\u7684\u4f18\u52bf\uff0c\u5e76\u80fd\u591f\u7ef4\u62a4\u591a\u4e2a\u5e76\u884c\u7684\u7f16\u8f91\u8def\u5f84\u3002"
        }
    },
    {
        "id": 184,
        "name": "MarkdownNote",
        "prompts": {
            "text": "[tutorial](http://docs.comfy.org/tutorials/flux/flux-1-kontext-dev) | [\u6559\u7a0b](http://docs.comfy.org/zh-CN/tutorials/flux/flux-1-kontext-dev)\n\n**diffusion model**\n\n- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)\n\n**text encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\nModel Storage Location\n\n```\n\ud83d\udcc2 ComfyUI/\n\u251c\u2500\u2500 \ud83d\udcc2 models/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc2 diffusion_models/\n\u2502   \u2502   \u2514\u2500\u2500 flux1-dev-kontext_fp8_scaled.safetensors\n\u2502   \u251c\u2500\u2500 \ud83d\udcc2 vae/\n\u2502   \u2502   \u2514\u2500\u2500 ae.safetensor\n\u2502   \u2514\u2500\u2500 \ud83d\udcc2 text_encoders/\n\u2502       \u251c\u2500\u2500 clip_l.safetensors\n\u2502       \u2514\u2500\u2500 t5xxl_fp16.safetensors \u6216\u8005 t5xxl_fp8_e4m3fn_scaled.safetensors\n```\n"
        }
    },
    {
        "id": 185,
        "name": "MarkdownNote",
        "prompts": {
            "text": "For reference:\n- **fp8_scaled**: Requires about 20GB of VRAM.\n- **Original**: Requires about 32GB of VRAM.\n\n---\n\n\u4f9b\u53c2\u8003\uff1a\n-  **fp8_scaled** :  \u5927\u6982\u9700\u8981 20GB \u5de6\u53f3 VRAM \n- **\u539f\u59cb\u6743\u91cd**:  \u539f\u59cb\u6743\u91cd\uff0c\u5927\u6982\u9700\u8981 32GB \u5de6\u53f3 VRAM \n"
        }
    },
    {
        "id": 186,
        "name": "MarkdownNote",
        "prompts": {
            "text": "\n## Flux Kontext Prompt Techniques\n\n### 1. Basic Modifications\n- Simple and direct: `\"Change the car color to red\"`\n- Maintain style: `\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. Style Transfer\n**Principles:**\n- Clearly name style: `\"Transform to Bauhaus art style\"`\n- Describe characteristics: `\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- Preserve composition: `\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. Character Consistency\n**Framework:**\n- Specific description: `\"The woman with short black hair\"` instead of \"she\"\n- Preserve features: `\"while maintaining the same facial features, hairstyle, and expression\"`\n- Step-by-step modifications: Change background first, then actions\n\n### 4. Text Editing\n- Use quotes: `\"Replace 'joy' with 'BFL'\"`\n- Maintain format: `\"Replace text while maintaining the same font style\"`\n\n## Common Problem Solutions\n\n### Character Changes Too Much\n\u274c Wrong: `\"Transform the person into a Viking\"`\n\u2705 Correct: `\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### Composition Position Changes\n\u274c Wrong: `\"Put him on a beach\"`\n\u2705 Correct: `\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### Style Application Inaccuracy\n\u274c Wrong: `\"Make it a sketch\"`\n\u2705 Correct: `\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## Core Principles\n\n1. **Be Specific and Clear** - Use precise descriptions, avoid vague terms\n2. **Step-by-step Editing** - Break complex modifications into multiple simple steps\n3. **Explicit Preservation** - State what should remain unchanged\n4. **Verb Selection** - Use \"change\", \"replace\" rather than \"transform\"\n\n## Best Practice Templates\n\n**Object Modification:**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**Style Transfer:**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**Background Replacement:**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**Text Editing:**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **Remember:** The more specific, the better. Kontext excels at understanding detailed instructions and maintaining consistency. "
        }
    },
    {
        "id": 187,
        "name": "MarkdownNote",
        "prompts": {
            "text": "\n## Flux Kontext \u63d0\u793a\u8bcd\u6280\u5de7\n\n\u4f7f\u7528\u82f1\u6587\n\n### 1. \u57fa\u7840\u4fee\u6539\n- \u7b80\u5355\u76f4\u63a5\uff1a`\"Change the car color to red\"`\n- \u4fdd\u6301\u98ce\u683c\uff1a`\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. \u98ce\u683c\u8f6c\u6362\n**\u539f\u5219\uff1a**\n- \u660e\u786e\u547d\u540d\u98ce\u683c\uff1a`\"Transform to Bauhaus art style\"`\n- \u63cf\u8ff0\u7279\u5f81\uff1a`\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- \u4fdd\u7559\u6784\u56fe\uff1a`\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. \u89d2\u8272\u4e00\u81f4\u6027\n**\u6846\u67b6\uff1a**\n- \u5177\u4f53\u63cf\u8ff0\uff1a`\"The woman with short black hair\"`\u800c\u975e`\"\u5979\"`\n- \u4fdd\u7559\u7279\u5f81\uff1a`\"while maintaining the same facial features, hairstyle, and expression\"`\n- \u5206\u6b65\u4fee\u6539\uff1a\u5148\u6539\u80cc\u666f\uff0c\u518d\u6539\u52a8\u4f5c\n\n### 4. \u6587\u672c\u7f16\u8f91\n- \u4f7f\u7528\u5f15\u53f7\uff1a`\"Replace 'joy' with 'BFL'\"`\n- \u4fdd\u6301\u683c\u5f0f\uff1a`\"Replace text while maintaining the same font style\"`\n\n## \u5e38\u89c1\u95ee\u9898\u89e3\u51b3\n\n### \u89d2\u8272\u53d8\u5316\u8fc7\u5927\n\u274c \u9519\u8bef\uff1a`\"Transform the person into a Viking\"`\n\u2705 \u6b63\u786e\uff1a`\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### \u6784\u56fe\u4f4d\u7f6e\u6539\u53d8\n\u274c \u9519\u8bef\uff1a`\"Put him on a beach\"`\n\u2705 \u6b63\u786e\uff1a`\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### \u98ce\u683c\u5e94\u7528\u4e0d\u51c6\u786e\n\u274c \u9519\u8bef\uff1a`\"Make it a sketch\"`\n\u2705 \u6b63\u786e\uff1a`\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## \u6838\u5fc3\u539f\u5219\n\n1. **\u5177\u4f53\u660e\u786e** - \u4f7f\u7528\u7cbe\u786e\u63cf\u8ff0\uff0c\u907f\u514d\u6a21\u7cca\u8bcd\u6c47\n2. **\u5206\u6b65\u7f16\u8f91** - \u590d\u6742\u4fee\u6539\u5206\u4e3a\u591a\u4e2a\u7b80\u5355\u6b65\u9aa4\n3. **\u660e\u786e\u4fdd\u7559** - \u8bf4\u660e\u54ea\u4e9b\u8981\u4fdd\u6301\u4e0d\u53d8\n4. **\u52a8\u8bcd\u9009\u62e9** - \u7528\"\u66f4\u6539\"\u3001\"\u66ff\u6362\"\u800c\u975e\"\u8f6c\u6362\"\n\n## \u6700\u4f73\u5b9e\u8df5\u6a21\u677f\n\n**\u5bf9\u8c61\u4fee\u6539\uff1a**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**\u98ce\u683c\u8f6c\u6362\uff1a**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**\u80cc\u666f\u66ff\u6362\uff1a**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**\u6587\u672c\u7f16\u8f91\uff1a**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **\u8bb0\u4f4f\uff1a** \u8d8a\u5177\u4f53\u8d8a\u597d\uff0cKontext \u64c5\u957f\u7406\u89e3\u8be6\u7ec6\u6307\u4ee4\u5e76\u4fdd\u6301\u4e00\u81f4\u6027\u3002"
        }
    },
    {
        "id": 188,
        "name": "EmptySD3LatentImage"
    },
    {
        "id": 189,
        "name": "UnetLoaderGGUF",
        "prompts": {
            "text": "flux1-kontext-dev-Q4_K_M.gguf"
        }
    },
    {
        "id": 190,
        "name": "DualCLIPLoader",
        "prompts": {
            "text": "t5xxl_fp8_e4m3fn.safetensors",
            "text_2": "clip_l.safetensors"
        }
    },
    {
        "id": 191,
        "name": "VAELoader",
        "prompts": {
            "text": "ae.safetensors"
        }
    },
    {
        "id": 193,
        "name": "VAEDecode"
    },
    {
        "id": 194,
        "name": "LoadImage",
        "prompts": {
            "text": "7FCD24DFEFF252F27D1E9526C6E3D1C0.jpg"
        }
    },
    {
        "id": 195,
        "name": "translators",
        "prompts": {
            "text": "\u5bf9\u8fd9\u4e9b\u52a8\u6f2b\u4eba\u7269\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u9762\u90e8\u7279\u5f81\uff0c\u8ba9\u7ea2\u8272\u8863\u670d\u7684\u52a8\u6f2b\u5973\u5b69\u5bf9\u6df1\u8272\u8863\u670d\u7684\u52a8\u6f2b\u5973\u5b69\u62e5\u62b1\u3002",
            "text_2": "english(en)"
        }
    },
    {
        "id": 198,
        "name": "LoadImage",
        "prompts": {
            "text": "C09C6C74AEE442071098EDF52054DC18.jpg"
        }
    },
    {
        "id": 199,
        "name": "AnyImagetoConditioning_flux_kontext"
    },
    {
        "id": 200,
        "name": "LoadImage",
        "prompts": {
            "text": "ComfyUI_00474_.png"
        }
    },
    {
        "id": 201,
        "name": "LoadImage",
        "prompts": {
            "text": "8037355.webp"
        }
    },
    {
        "id": 202,
        "name": "LoadImage",
        "prompts": {
            "text": "ComfyUI_00001_.png"
        }
    },
    {
        "id": 203,
        "name": "LoadImage",
        "prompts": {
            "text": "temp_image_912.png"
        }
    },
    {
        "id": 204,
        "name": "MarkdownNote",
        "prompts": {
            "text": "[bullerwins/FLUX.1-Kontext-dev-GGUF](https://huggingface.co/bullerwins/FLUX.1-Kontext-dev-GGUF)"
        }
    },
    {
        "id": 205,
        "name": "VAEEncode"
    },
    {
        "id": 206,
        "name": "FluxKontextImageScale"
    },
    {
        "id": 207,
        "name": "ReferenceLatent"
    },
    {
        "id": 208,
        "name": "Environment_INFO",
        "prompts": {
            "text": "============================================================\nENVIRONMENT INFO\n============================================================\n\n[SYSTEM INFORMATION]\nDate: 2025-06-27 20:41:44\nPlatform: Windows-10-10.0.19045-SP0\nSystem: Windows\nProcessor: AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD\nPython Version: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:29:11) [MSC v.1935 64 bit (AMD64)]\nComfyUI Version: 0.3.42\n\n[HARDWARE INFORMATION]\nPhysical CPU Cores: 6\nLogical CPU Cores: 12\nCPU Usage: 17.3%\nRAM Total: 31.93 GB\nRAM Available: 21.35 GB\nRAM Used: 33.1%\n\n[GPU INFORMATION]\nGPU 0:\n  Name: NVIDIA GeForce RTX 4060 Ti\n  Driver Version: 576.80\n  VRAM Total: 16.0 GB\n  VRAM Used: 1.65 GB\n  GPU Utilization: 11%\n\n[DEEP LEARNING FRAMEWORKS]\nPyTorch Version: 2.6.0+cu124\nCUDA Available: Yes\nCUDA Version: 12.4\ncuDNN Version: 90100\n\n============================================================"
        }
    },
    {
        "id": 209,
        "name": "MarkdownNote",
        "prompts": {
            "text": "[ComfyUI-MakkiTools\n](https://github.com/MakkiShizu/ComfyUI-MakkiTools)"
        }
    },
    {
        "id": 210,
        "name": "ShowText|pysssss",
        "prompts": {
            "text": "Maintain the same facial features for these anime characters while having the anime girl in red embrace the anime girl in dark clothes."
        }
    }
]