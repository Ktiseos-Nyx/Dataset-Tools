{
  "last_node_id": 59,
  "last_link_id": 91,
  "nodes": [
    {
      "id": 22,
      "type": "MZ_ChatGLM3_V2",
      "pos": [
        570,
        860
      ],
      "size": {
        "0": 395,
        "1": 205
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "chatglm3_model",
          "type": "CHATGLM3MODEL",
          "link": 29,
          "label": "chatglm3_model"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            81
          ],
          "shape": 3,
          "label": "CONDITIONING",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "MZ_ChatGLM3_V2"
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 9,
      "type": "VAEDecode",
      "pos": [
        2080,
        570
      ],
      "size": {
        "0": 140,
        "1": 46
      },
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 84,
          "label": "Latent"
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 9,
          "label": "VAE",
          "slot_index": 1
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            85
          ],
          "shape": 3,
          "label": "图像",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 51,
      "type": "KSampler",
      "pos": [
        1720,
        570
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 83
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 82
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 81
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 80
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            84
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1069832286697578,
        "randomize",
        20,
        4.5,
        "dpmpp_2m_sde_gpu",
        "karras",
        1
      ]
    },
    {
      "id": 1,
      "type": "MZ_ChatGLM3Loader",
      "pos": [
        110,
        590
      ],
      "size": {
        "0": 284.8618469238281,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "chatglm3_model",
          "type": "CHATGLM3MODEL",
          "links": [
            27,
            29
          ],
          "shape": 3,
          "label": "chatglm3_model",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "MZ_ChatGLM3Loader"
      },
      "widgets_values": [
        "checkpoints\\chatglm3-8bit.safetensors"
      ]
    },
    {
      "id": 10,
      "type": "VAELoader",
      "pos": [
        110,
        850
      ],
      "size": {
        "0": 282.26361083984375,
        "1": 61.20377731323242
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            9
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "sdxl_vae_fixed.safetensors"
      ]
    },
    {
      "id": 46,
      "type": "IPAdapterModelLoader",
      "pos": [
        30,
        260
      ],
      "size": {
        "0": 282.26361083984375,
        "1": 58
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            86
          ],
          "shape": 3,
          "label": "IPAdapter",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "kolors\\ip_adapter_plus_general.bin"
      ]
    },
    {
      "id": 53,
      "type": "easy setNode",
      "pos": [
        30,
        210
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "link": 86
        }
      ],
      "title": "Set_IPAdapter",
      "properties": {
        "previousName": "IPAdapter"
      },
      "widgets_values": [
        "IPAdapter"
      ],
      "color": "#223"
    },
    {
      "id": 55,
      "type": "easy setNode",
      "pos": [
        30,
        360
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "link": 87
        }
      ],
      "title": "Set_CLIP_VISION",
      "properties": {
        "previousName": "CLIP_VISION"
      },
      "widgets_values": [
        "CLIP_VISION"
      ],
      "color": "#223"
    },
    {
      "id": 20,
      "type": "MZ_KolorsUNETLoaderV2",
      "pos": [
        30,
        100
      ],
      "size": {
        "0": 373.7890319824219,
        "1": 58
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "model",
          "type": "MODEL",
          "links": [
            90
          ],
          "shape": 3,
          "label": "model",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "MZ_KolorsUNETLoaderV2"
      },
      "widgets_values": [
        "Kolors\\diffusion_pytorch_model.fp16.safetensors"
      ]
    },
    {
      "id": 58,
      "type": "easy setNode",
      "pos": [
        30,
        60
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "link": 90
        }
      ],
      "title": "Set_model",
      "properties": {
        "previousName": "model"
      },
      "widgets_values": [
        "model"
      ],
      "color": "#223"
    },
    {
      "id": 59,
      "type": "easy getNode",
      "pos": [
        1320,
        20
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            91
          ],
          "slot_index": 0
        }
      ],
      "title": "Get_model",
      "properties": {},
      "widgets_values": [
        "model"
      ],
      "color": "#223"
    },
    {
      "id": 57,
      "type": "easy getNode",
      "pos": [
        1320,
        50
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 5,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            89
          ],
          "slot_index": 0
        }
      ],
      "title": "Get_IPAdapter",
      "properties": {},
      "widgets_values": [
        "IPAdapter"
      ],
      "color": "#223"
    },
    {
      "id": 56,
      "type": "easy getNode",
      "pos": [
        1320,
        90
      ],
      "size": {
        "0": 210,
        "1": 58
      },
      "flags": {
        "collapsed": true
      },
      "order": 6,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            88
          ],
          "slot_index": 0
        }
      ],
      "title": "Get_CLIP_VISION",
      "properties": {},
      "widgets_values": [
        "CLIP_VISION"
      ],
      "color": "#223"
    },
    {
      "id": 7,
      "type": "EmptyLatentImage",
      "pos": [
        999,
        668
      ],
      "size": {
        "0": 210,
        "1": 106
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            80
          ],
          "shape": 3,
          "label": "Latent"
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        768,
        1024,
        1
      ]
    },
    {
      "id": 54,
      "type": "CLIPVisionLoader",
      "pos": [
        30,
        400
      ],
      "size": {
        "0": 278.2551574707031,
        "1": 58
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            87
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "kolors\\pytorch_model.bin"
      ]
    },
    {
      "id": 27,
      "type": "LoadImage",
      "pos": [
        540,
        -90
      ],
      "size": {
        "0": 664.998046875,
        "1": 605.7599487304688
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            75
          ],
          "shape": 3,
          "label": "图像",
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3,
          "label": "遮罩"
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "00002-LotusMIX-V1_2313748910.png",
        "image"
      ]
    },
    {
      "id": 21,
      "type": "MZ_ChatGLM3_V2",
      "pos": [
        570,
        590
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "chatglm3_model",
          "type": "CHATGLM3MODEL",
          "link": 27,
          "label": "chatglm3_model"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            82
          ],
          "shape": 3,
          "label": "CONDITIONING",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "MZ_ChatGLM3_V2"
      },
      "widgets_values": [
        "cinematic photograph of a woman"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 50,
      "type": "IPAdapterAdvanced",
      "pos": [
        1310,
        160
      ],
      "size": {
        "0": 315,
        "1": 278
      },
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 91
        },
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 89
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 75
        },
        {
          "name": "image_negative",
          "type": "IMAGE",
          "link": null
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 88
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            83
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterAdvanced"
      },
      "widgets_values": [
        1,
        "linear",
        "concat",
        0,
        1,
        "V only"
      ]
    },
    {
      "id": 52,
      "type": "SaveImage",
      "pos": [
        2290,
        570
      ],
      "size": {
        "0": 635.3220825195312,
        "1": 455.3147888183594
      },
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 85
        }
      ],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "./koda/ipa/koda"
      ]
    },
    {
      "id": 48,
      "type": "Note",
      "pos": [
        -542,
        41
      ],
      "size": {
        "0": 512.2986450195312,
        "1": 406.68133544921875
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "koda-ipa-basic-v8\n\nVideo: https://www.youtube.com/watch?v=3Vcdg5ocjO4\nWorkflow: https://civitai.com/models/589666\n\nKoda Pack v1\nNew Base Model - Kolor\n\nip adapter basic\n\n\n\nYou will need:\ninstall any and all missing custom nodes & use the latest version of ComfyUI\n\n\nhttps://huggingface.co/Kijai/ChatGLM3-safetensors/tree/main\n\ndownload one of the models, i will use the fp8 version, you might use another.\n\nplace inside ComfyUI\\models\\LLM\\checkpoints\\\n\nhttps://huggingface.co/Kwai-Kolors/Kolors/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors\n\nplace inside ComfyUI/models/unet/diffusers/kolors\n\nhttps://huggingface.co/Kwai-Kolors/Kolors\n\nI also added all of these files from diffusers here.\nwe already downloaded the \"diffusion_pytorch_model.fp16.safetensors\" and put it into the /models/unet/kolors/ some of the nodes look in a different location, it's up to you which method you want to use as both will work, this is discussed in the video.\n\nWe do not need any .bin of the contents of text_encoder because we took the ChatGLM3.fp8.safetensors instead.\n\nstructure of ComfyUI\\models\\diffusers\\Kolors\\\n\nComfyUI\\models\\diffusers\\Kolors> tree /F\n│   model_index.json\n│\n├───scheduler\n│       scheduler_config.json\n│\n├───text_encoder\n│       config.json\n│       tokenizer.model\n│       tokenizer_config.json\n│       vocab.txt\n│\n└───unet\n        config.json\n        diffusion_pytorch_model.fp16.safetensors\nKolors IP Adapter\nhttps://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus\n\ndownload ip_adapter_plus_general.bin\n\nplace inside \\models\\ipadapter\\kolors\\\n\nKolors Clip Vision\nhttps://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/tree/main/image_encoder\n\ndownload pytorch_model.bin\n\nplace inside \\models\\clip_vision\\kolors\\\n\nhttps://civitai.com/models/441432/mistoline\n\nplace inside \\models\\controlnet\\kolors\\\n\nI'm suggesting a subfolder, or if you prefer rename them as needed.\n\nVAE\nFor all the VAE - just use your favorite SDXL VAE"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      9,
      10,
      0,
      9,
      1,
      "VAE"
    ],
    [
      27,
      1,
      0,
      21,
      0,
      "CHATGLM3MODEL"
    ],
    [
      29,
      1,
      0,
      22,
      0,
      "CHATGLM3MODEL"
    ],
    [
      75,
      27,
      0,
      50,
      2,
      "IMAGE"
    ],
    [
      80,
      7,
      0,
      51,
      3,
      "LATENT"
    ],
    [
      81,
      22,
      0,
      51,
      2,
      "CONDITIONING"
    ],
    [
      82,
      21,
      0,
      51,
      1,
      "CONDITIONING"
    ],
    [
      83,
      50,
      0,
      51,
      0,
      "MODEL"
    ],
    [
      84,
      51,
      0,
      9,
      0,
      "LATENT"
    ],
    [
      85,
      9,
      0,
      52,
      0,
      "IMAGE"
    ],
    [
      86,
      46,
      0,
      53,
      0,
      "*"
    ],
    [
      87,
      54,
      0,
      55,
      0,
      "*"
    ],
    [
      88,
      56,
      0,
      50,
      5,
      "CLIP_VISION"
    ],
    [
      89,
      57,
      0,
      50,
      1,
      "IPADAPTER"
    ],
    [
      90,
      20,
      0,
      58,
      0,
      "*"
    ],
    [
      91,
      59,
      0,
      50,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 2.1435888100000016,
      "offset": [
        648.5214992199178,
        -21.680028873414145
      ]
    }
  },
  "version": 0.4
}